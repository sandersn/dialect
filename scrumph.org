* Scrumph : Internal Scrum
** 2009/12/2
   - I re-arranged hypotheses. I marked up the methods intro with
     section numbers.
  - I will rewrite the headings of the methods section. I will
    re-arrange methods intro so the section numbers look less
    stupid. I will mail Sandra to set up a time on Friday to talk
    about the new methods sections.
  - Hypotheses section still sucks pretty bad. There is a lot of noise
    text left to be excised before giving a draft to Sandra.
** 2009/12/3
   - I rewrote the headings of the method sections. I re-arranged the
     methods intro so that at least the section 3 references are in
     order (though nested within section 5 references). I mailed
     Sandra and set up a time around 1:30. Maybe earlier; I will
     probably go to the reading group.
   - I will write stubs for unfinished method sections. I will rewrite
     the hypotheses section to remove the noise. I will clean up the
     whole thing for noise and send a copy to Sandra.
** 2009/12/4
   - I wrote stubs for the unfinished method sections. I rewrote the
     hypotheses sections to remove noise, along with the whole thing,
     and sent a copy to Sandra.
   - I will meet with Sandra to ask her about the appropriateness of
     the new subsections. I will expand the ones that I keep as much
     as I can, then do additional research to find out what to put in
     the others.
   - I have a ton of errands to run. Probably I should turn in my
     Swedish book soon and try to find one that  actually has
     linguists in mind.
** 2009/12/7
   - I met with Sandra, she gave me some advice. I did research on
     kinds of backoff and wrote up a couple of the sections.
   - I will finish research for alternate distance measures section,
     write up all sections, and maybe start making them sound good.
   - 
** 2009/12/8
   - I finished research alternate distance measures section and wrote
     up all sections. None of them sound particularly good.
   - I will make all sections sound good.
   - Some of the section sstill need a little research and some
     citation (textbooks, mainly, though)
** 2009/12/9
   - I made all the sections sound good, except for the last sentence
     of each one. ugh. I added citations from the appropriate papers
     where they were missing.
   - I will double-check the last stupid-sounding sentences and
     re-read the whole methods section, then send to Sandra. The rest
     of the day I will work on converting to git (installing on
     peregrin if needed), resolving unicode problems in Consts.hs and
     investigate the lexicalisation of the Berkeley parser.
** 2009/12/10
   - I added more than I thought I'd have to to the proposal, then
     sent it off to Sandra. I switched to the more reliable way of
     storing non-standard diacritic sequences in Haskell in Consts.hs.
   - I will start testing the build process with tagPos, because it
     calls Swedia.extractTnt, which I'm working on. I will verify that
     both the Python and Haskell versions reproduce all the relevant
     words from the interviews.
   - Lexicalisation of the Berkeley parser (trainCfg) is delayed until
     testing tagPos and tagDep are tested. Also I need to figure out
     a programmatic way to verify the extractTnt output.
** 2009/12/11
   - I finished the switch to git with a massive cleanup and addition
     of some overlooked files to source control. I fixed a couple of
     bugs with Swedia.hs and then found a couple more that I missed.
   - I need to write some tests for Swedia. But I also need to move on
     to the other parts of the experiment.
   - I should probably (re?)download HUnit and QuickCheck
** 2009/12/14
   - I wrote some tests for Swedia. They aren't very good and I
     haven't integrated them into any kind of build I updated HUnit
     and QuickCheck to newest versions.
   - I will make sure my entire experiment still builds. I will figure
     out what test data to work with, either fake files or fake
     literals or a real file/directory.
   - Pretty soon I need to work on ConvertTalbankenToPTB so I can run
     Berkeley results. Also I need to make sure banks can
     build my entire experiment; it's a lot faster than jones and all
     of my corpora are free so I might as well copy them over.
** 2009/12/16
   - I checked that tagPos builds and got testing of swedia to run. I
     did not figure out what test data to use.
   - I will figure out what test data to work with. I will re-read
     Convert..PTB code and some Talbanken files to remember how to get
     lexical items from the XML.
   - Need to set up connection to jones so I can test the build.
** 2009/12/17
   - I copied an example *.cha for testing. I wrote a skeleton for
     testing Convert* code, downloaded an exmple *.tiger.xml, and
     looked at the types to see which functions were pure vs impure.
   - I will write some tests for ConvertTalbankenToPTB, and keep an
     eye out for how to modify to include lexical items. I should test
     the entire build today too, in the background.
   - 
** 2009/12/28
   - I wrote some tests, modified ConvertTagsToTxt to use lexical
     items, and re-ran the Berkeley parser on this. Haven't got the
     results yet.
   - I guess I will test my lexical subset code for talbanken. Except
     I don't have talbanken so I guess I'll just use some txt file.
   - I need to check the parser results and start running R on them.
   - Note: I fixed a critical (?) bug in ConvertTagsToTxt. Before
     lexicalising, sentenceEnd was wrong, meaning that (groupBy
     sentenceEnd) was wrong, meaning that everything was one long
     sentence??
** 2009/12/29
   - I wrote a bunch of tests for ConvertTagsToTxt. Maybe others? I
     can't remember.
   - I will write more tests, mostly for ConvertTagsTo[Conll|Txt]
   - I wish I knew how to lift all from Bool to QuickCheck Property.
** 2009/12/30
   - I wrote a bunch of tests for TestConvertTags. I got the skeleton
     for TestPath up.
   - I will write tests for DepPath. I might start planning my
     dissertation chapter layout.
   - I am blocked on testing Path and testing modifications to the
     entire build; I need network access for that.
** 2010/01/04
   - I wrote tests for DepPath and planned my dissertation writing
     effort. It is below under *Plan.
   - I will fix DepPath and research Latex chapters. I will rerun
     everything from the top once I find out how long Yuyin's lopar
     will run. (I should e-mail her). I might need to prioritise the
     switch to banks.
   - It appears that I am getting significant results and that I
     didn't understand the output. '.' contributes to significance;
     '*' does not. HOWEVER, I was getting significant results on
     erroneous Dep formatted stuff, so who knows. This is like the 3rd
     time this has happened ok.
** 2010/01/05
   - I mostly fixed DepPath and downloaded the IU dissertation style
     sheet (as of 1999, in the Math department). I was misreading the
     output, and I am getting significant results! I am not sure what
     the distances are, though. It's only printing '1' for all, which
     I do not think is an average. I need to check the code again.
   - Today I will only test only running the experiment on banks if I
     have time. If I have still more time, I'll start figuring out how
     to parellelise it using multi-run.
   - Still need to make DepPath print the region name at the top of
     the file.
** 2010/01/06
   - I got multi-run working and it is super fast. I also fixed
     DepPath for real.
   - Today I will (1) reorganise icectrl.cpp so that only the
     currently used code is in the main file, and everthing else is in
     an include file. I will also chop up my proposal into
     dissertation chapters and paste the pieces in.
   - Still need to re-run DepPath.
** 2010/01/07
   - I reorganise icectrl into 3 files, changed the name to icesig.cpp,
     and added icedist.cpp. I dumped the distances and loaded them
     into Excel. I pasted a bunch of proposal text into my
     dissertation, plus some qual paper.
   - I will dump R tables and generate histograms. I will download a
     map from bing of Sweden and annotate it with pixel locations so I
     can figure out the distances in order to have geographic distnace
     matrix also.
   - Later I also need to write C++ to dump the features comparing an
     entire region to an entire other region. Then I can read them
     with something decent like Python or Haskell and do some
     analysis.
     I should also paste some of the detailed methods from my qual
     paper into the methods chapter. There is some detailed discussion
     of R, normalisation and leaf-ancestor paths.
** 2010/01/08
   - I annotated a list of locations with their relative geographical
     location. I dumped all data to R-format text tables. I generated
     PDF cluster diagrams (Ward's method worked best).
   - I will run the correlations and establish which are
     significant. I will write them up. I will make a nice diagram for
     visualising the clusters on the map of Sweden. I will write code
     to dump the diffs between the features of each set.
   - Tomorrow I should start putting all the diagrams into the
     dissertation.
** 2010/01/11
   - I ran correlations, found the significant ones and put them in a
     Latex table. I downloaded OmniGraffle and marked up the SVG/PDF
     map of Sweden from Wikipedia (available under CC GPL-Like
     licence). I wrote the code to dump per-feature diffs in C++. Then
     I wrote some Haskell code that reads in each file and (currently)
     prints the header plus the top and bottom 5 features. I ran it
     but there are way too many features to look at.
   - I will create a dict in consts of the Agree or Dep clusters,
     write some code in Norte to concat files sans the header (which I
     now think is a bad idea), then run the feature extraction on
     them. This will make only 10 comparisons to look at instead of
     528.
   - Need To pay for Omnigraffle--find out how to get academic
     discount
** 2010/01/12
   - I created a consts.py dict to map agree-clusters to sites, then
     wrote some code in norte.py to produce cluster feature
     analyses. Since I don't delete tmp files, RankFeatures extracts
     every comparison: 528 + 10. I cut the last 10 out and pasted them
     in results.tex. I also reformatted the Swedia cluster map to use
     larger fonts and coloured dots.
   - I will figure out a way to visualise and analyse the top feature
     differences between clusters (maybe Excel?). I will format them
     nicely in the results section. I will re-format the clusters so
     that they fit the page. I will work on pasting some more methods
     in and then look at the intro/hypotheses--I'm still not sure how
     that should go.
   - 
** 2010/01/13
   - I put the top 5 top/bottom features from each cluter in Excel and
     wrote some short analysis on the strength of each cluster. I
     reformatted clusters. I pasted in some more method detail from my
     qual paper and wrote some more on the intro.
   - I will download RuG-L04's newest version and get it to generate
     nice diagrams. I will re-read my intro and figure out what goes
     in between the introductory material and the hypotheses. Or after
     them. I should look at Heeringa's thesis again.
   - 
** 2010/01/14
   - I downloaded and figured out L04's basics. I didn't reread my
     intro. I don't have borders to my map, but I did include it
     already in the dissertation.
   - I will spend a couple of hours trying to add simple borders to
     the L04 maps and then re-read my intro.
   - I should upload a copy of dissertation.tex so that I can show
     Sandra. Also I need to print an invoice and check that AFP still
     works on jones.
     Also I should ask Sandra when /how much I should start sending on
     to Henrik Rosenkvist.
** 2010/01/15
   - I got simple borders added to the MDS diagrams from L04. I
     started an overview section at the end of the background
     chapter. I tweaked the wording earlier in the chapter, but didn't
     touch the hypotheses from the proposal.
   - I will meet with Sandra to find out what I still need to do on
     the proposal. I will also ask her about variations on the
     results, general layout of the dissertation, organisation of the
     first chapter (maybe) and when/how much results to send to
     Henrik Rosenkvist.
   - Still not sure what to do about hypotheses in the background
     chapter.
     Later today: create hypotheses separate chapter, generate
     figures for POS run and see how good they are. Revise proposal
     with Sandra's revisions.
** 2010/01/18
   - I met with Sandra and got the changes to make for the proposal,
     plus advice of who to talk to, plus some suggestions for
     dissertation layout and experimental paths.
   - I will make the proposal revisions today. I will probably have
     enough time to implement Sandra's redep idea too.
   - I need to draft e-mails to Henrik Rosenkvist and Rex Sprouse
     asking for (1) inspection of my results and Swedish syntactic
     dialectology papers and (2) inspection of TnT/Berkeley/Malt's
     annotation outputs.
     I will probably need a better way to visualise them because he is
     a german syntactician and may (may not?) have even worked with
     dependencies. Actually this holds for Rosenkvist too...
** 2010/01/19
   - I made the proposal revisions. I implemented (badly/mostly) the
     redep idea. It appears to be working.
   - I will run redep. I will edit the later steps to account for
     redep. I will mail my committee members. I will look at the
     hypotheses chapter and figure out what to do with it.
   - Still need to mail Rosenkvist and Sprouse.
** 2010/01/20
   - I mailed my committee members. I wrote KL divergence and JS
     divergence, and ran them along with redep after editing
     build.py to account for 3x4 variations. I finished
     generating r-redep figures. I did not look at the hypotheses chapter.
   - I will continue mailing committee members to find out whether
     next week or the week after that is good. I will make a
     presentation of Work So Far and To Do, divided into
     Analysis and Writing. I will outline a bing presentation for the
     end of the month too.
   - Remember to mail Rachel, take out the trash, and find a present
     for Mom (and maybe Daniel)!
     Still need to mail Rosenkvist and Sprouse.
     Maybe should run r^2 too, now that I'm running all these others.
** 2010/01/21
   - I mailed committee members some more. Looks like it will be in
     the afternoon. I made a proposal defence presentation (draft) and
     a bing presentation. Looks like I will give them the same day.
   - Need to mail one last time. I will start composing a mail to
     Rosenkvist. I will add r^2 and dependency arc labels and rerun everything
     with them. I will start doing SOMETHING to questions.tex.
   - Need to mail my Friendspeak partner too. Argh, Mail!
** 2010/01/22
   - I mailed Rosenkvist. I wrote a couple of pages of stuff for the
     first question. I added r^2 and dependency arc labels and reran
     everything. I made a little chart of significances. They are not
     consistent. I did not mail the committee members.
   - I will mail Rex Sprouse. Include an example sentence to get
     him interested. I will mail my committee members. I will write a
     couple of pages for the second hypothesis and a couple for
     alternate measures.
   - 
** 2010/01/25
   - I wrote a few pages for the second hypothesis and some more for
     alternate measures. I made some diagrams for constituency and
     dependency parses and I don't need Rex's help to see how bad they
     are.
   - I will implement real trigrams and call the current retrigram. I
     will implement unigram/reunigram for comparison. I will filter
     the http://uit.no/scandiasyn/bib2003 list down to Swedish ones. I
     will bug my committee to finalise the proposal defence.
   - I should also reply to Henrik.
** 2010/01/26
   - I implemented real trigrams and unigrams and re-ran everything.
     I filtered the uit.no
     list down to Swedish ones (probably). I wrote an R script that
     does some of the correlation/significance/figure work for me. I
     wrote a status e-mail to Sandra.
   - I will work a whole bunch on Questions and maybe a little on the
     intro (although the summary is pretty hard to write until the
     rest is written). I will look over the proposal defence again and
     see if anything more occurs to me.
   - Still need to track down those articles and start reading
     them. Should also reply to Henrik soon. Not sure what to say.
** 2010/01/27
   - I wrote second draft on the first question and sstarted alternate
     measures. I looked at the proposal defence for like 20 seconds. I
     added some results instead of . I read a little more about R.
   - I will finish Questions with the Features question and finishing
     Alternate Measures. I will try to learn a bit more about R so I
     can finish automating the significance tests. I will look more at
     the proposal defence.
   - I should STILL mail Rosenkvist and start reading those
     papers. (besides the apparent cleft one)
* Plan
** January
*** Get results
**** DONE Try lexicalised vs POS
     Lexicalised doesn't work. The end.
**** DONE Try paths of dependency labels instead of POSs
**** TODO Try lexical cleaning
**** TODO Try different parameters to parsers
**** DONE Move experiment to Banks
**** DONE Try different distance measures
     This should be pretty simple. Right? Just different for loops.
     Even C++ can't muck this up too much.
**** DONE Try different regions
     the current ones are smallest and don't need the additional
     precision
*** Introduction
**** DONE Figure out how to structure latex chapters
**** TODO Introduction
     Need to write the overview of the dissertation. Need about a page
     here explaining what each chapter is.
**** TODO Hypotheses
     Pretty good rough draft, needs a lot of work to be presentable.
** February
*** Revise Hypotheses
**** TODO Get Sandra (and others?) to look over it and critique.
     It probably isn't nearly what is needed.
*** Start Analysis
**** TODO Read up on Swedish [syntactic] dialectology
**** TODO Work with Rosenkvist to find out how my results compare to it
*** Methods
** March
*** Results
** April
*** Discussion
** May
*** Cleanup and Defence
** June
*** Slop/revisions
* TODO Maybe should clean lexically more aggresively, esp punctuation (non .)

  Do this by
  liftM2 Set.difference
    (getDirectoryContents "." >>= wds ".t")
    (getDirectoryContents "." >>= wds "talbanken*.???")
    where wds ext = filter (isSuffixOf ext)
                    & mapM (readFile & liftM words)
                    & liftM (concat & Set.fromList)
  swediaSet = set()
  talbankenSet = set()
  for f in os.dir("."):
    if f.endswith(".t"):
      swediaSet += wds(f)
    elif f.endswith(".talbanken"):
      talbankenSet += wds(f)
  print talbankenSet - swediaSet
  def wds(f):
    return open(f).read().split()
  and see what common noise shows up
* TODO Find out how to do assertThrows in HUnit
* TODO Remember to upgrade blog software

ask local Swedish speaker to look over automatic annotation quality
esp Berkeley parser and its POS tagging quality

send around revised draft, ask to set up a meeting. Then prepare a
10-15 minute overview of what I am planning to do and what I have done
so far. They will read the draft and at the meeting decide whether I
have taken the right amount of work. I will field questions if
necessary.

* TODO Revise omnigraffle cluster maps
* TODO Make a 10-15 progress presentation
* TODO Res my bing end-of-internship presentation for Feb 2's CL meeting
* TODO Figure out how to properly combine features
* TODO Make a nicely formatted example sentence from each feature type
  To send to Rex Sprouse or the native Swedish speaker
