\chapter{Discussion}

This chapter discusses three topics:

\begin{enumerate}
\item Analysis of results: dissertation work on its own.
\item Comparison to Swedish syntactic dialectology.
\item Comparison to Swedish phonological dialectometry.
\item Conclusions: summary of discussion
\item and then summary of dissertation: contribution to dialectometry at large.
\end{enumerate}

However, I can get some of the discussion from my first qualifying
paper; the syntax distance method hasn't changed, it just works a lot
better on a dialect corpus.

A big question is why trigrams are so good. All of the fancier feature
sets do worse than trigrams.


\section{Analysis of Results}

% TODO: Need to add references to results chapter and also any
% citations

\subsection{Significance of Dialect Distance}

Analysis of the significance of dialect distance provides a measure of
how reliable the distances to be analysed later in this chapter are. A
distance that does not find significant distances between of 30
regions is not suitable for precise inspection, although small numbers
of non-significant distances will still allow less precise methods to
return interpretable results.

From the very few significant distances found by comparing whole
regions to regions, It is obvious that fix-sized sampling is needed to
work around size differences; sentence length normalisation does not
adequately adjust for the effects of having more sentences, nor is the
difference negligable as might be hoped. For the rest of the analysis,
whole-region sampling will be skipped in favour of 1000-sentence
fixed-size samples.

TODO: Comparison of frequencies is slightly more successful than
  comparison of ratios. (This also makes sense because of the noisy
  parsing as well as the smallish corpora)

\subsubsection{Significance by Measure}

The distance measures most likely to find significance are, in order,
cosine dissimilarity, Jensen-Shannon divergence and $R$. Cosine
similarity resulted in all significant distances, even for
part-of-speech unigrams. Unigrams are intended as a baseline and as
such, it is unexpected for. More on cosine similarity will explored
in later sections.

Of the two pairs of similar methods, it is not surprising that
Jenson-Shannon divergence provides more reliable results than
Kullback-Leibler divergence. Although both are called ``divergence'',
JS divergence is originally a dissimalarity, while KL divergence must
be converted to a dissimarility, which is symmetric, by measuring it
twice. Because of the placement of the logarithm in KL divergence, it
can only compare features that occur at least once in both corpora (see equation
\ref{klmeasure} in chapter \ref{methods-chapter}). It must skip
features unique to a single corpus in order to avoid division by zero.

On the other hand, there is no reason to expect that $R^2$ would
provide less reliable results than $R$---the only difference is that
$R$ sums the absolute difference in feature counts rather than the
squared difference. Yet $R$ consistently finds more significant
distances than $R^2$. This is backward from the expected result that
$R^2$ would exaggerate the most important feature differences by
squaring them. Furthermore, the difference is not uniform across feature
type; the differences are largest for leaf-ancestor paths and
arc-head paths.

In the following analysis, I will further investigate the causes for the difference
between $R$ and $R^2$, as well as investigate whether cosine
similarity's ability to find significant distances between practically
anything will extend to good results based on measures besides
statistical reliability.

\subsubsection{Significance by Feature Set}

% \item Unigrams do form an adequate baseline; they are bad but not too
%   bad.

The feature sets most likely to find significance are, in order,
trigrams, all combined features and leaf-head paths (both with
support-vector-machine training and with Timbl's instance-based
training). Without ratio normalisation, the other feature sets are not
much worse, but with it included, these three are the best by some
distance.

The relatively high quality of trigrams does not make sense given only
the linguistic facts; however, it is likely that the entirely
automatic annotation used here introduces more and more errors the
more annotators run, operating on the output of previous automatic
annotators. Trigrams are the result of only one
automatic annotation, and one for which the state of the art is at or
near human performance. So the fact that these particular trigrams are
of higher quality than these particular dependencies or constituencies
is probably the deciding factor in their higher number of significant
distances. Although it is impossible to tell from my results, I
predict that a manually annotated dialect corpus would show that
non-flat syntactic structure is helpful in producing significant
distances.

Given the above facts, the question should rather be: why are
leaf-head paths perform as well as they do? Better, for example, than
the leaf-ancestor paths on which they're modelled. It could be that
there is less room for error; many of the common leaf-head paths are
short: short interview sentences with simple structure make for
shorter leaf-head paths than leaf-ancestor paths. As a result, the
important leaf-head paths consist mainly of a couple of
parts-of-speech. But in that case, adding the ratio normalisation
should remove their advantage over leaf-ancestor paths, but it does
not.

Another reason could be a difference in parsers: MaltParser has been
tested before with Swedish (CITE). Besides English, the Berkeley
parser has been tested prominently on German and Chinese. Therefore,
the difference would better be explained by appealing to the
difference in parsers rather than an unsuitability of Swedish for
constituent analysis.

It is disappointing linguistically that trigrams provide the most
reliable results so far; a linguist would expect that including
syntactic information would make it easier to measure the differences
between regions. If it is, as hypothesised here, an effect of chaining
machine annotators, a study using manually annotated corpora could
detect this. However, it still means that trigrams are the most useful
feature set from a practical view, because automatic trigram tagging
is very close to human performance with little training. That means
the only required human work is the transcription of interviews in
most cases.

On the other hand, if additional features sets are to be developed for
a corpus, then combining all available features seems to be a
successful strategy. The distance measures seem to be able to use all
available information for finding significant distances.

\begin{enumerate}
\item In addition, their results call the cosine measure into question. Why is it so
  good at finding significant distances? Why are the maps it produces (below) so
  confusing and different from the others?
\end{enumerate}
\subsection{Correlation}
TODO: ALSO I should point out that geographic correlation IS the
default expected by normal old boring linguists. The Nordic Languages
is pretty clear on this plus I have some references from
dialectology papers.

Correlation with geographic distance or travel distance indicates that
a distance measure follows the expectations of linguists about
distribution of dialects. A lack of correlation does not mean that a
measure is useless, but presence of correlation means that the
distance measure asserts the well-known tendency of dialect
distributions to be more or less smoothly gradient over physical
space.

Taken as a whole, the distance measures are more likely to correlate
significantly with travel distance than with straight-line geographic
distance. This makes sense since the difficulty of moving from place
to place is what influences dialect formation, and taking roads into
account is an improved estimate over straight-line distance. It is
interesting, though, that there is such a difference given that geographic
and travel distance are themselves highly correlated.

Unlike the number of significant distances, there is a strong effect
of the ratio normalisation on the travel distance
correlations. Without the ratio normalisation, only cosine similarity
with trigram and unigram POS features correlate significantly with
travel distance. With ratio normalisation, quite a few of the
parameter settings correlate significantly with travel
distance. Notably, the trigram feature set and combined feature set
all correlate, except as measured by cosine similarity. As measured by
Kullback-Leibler divergence, a number of feature sets besides trigrams
also correlate significantly, but most of these are not valid because
the distances on which the correlation is based are not all significant.

% (On cosine's n-gram correlation with geography)
% TODO: This analysis ends with idle speculation. I should replace it
% with fevered speculation.
With ratio normalisation, once again cosine similarity measured over
unigram POS features correlates significantly with travel
distance. What's more, this is the {\it only} significant correlation
in the ratio normalised case for cosine. This seems strange. A
possible explanation is that unigrams are simpler, so the type count
is a higher than for other measures. But this distinction doesn't show up in
the 1000-sample size, which should have lower type counts because of
its limited size.

The results of travel distance correlation indicate that ratio
normalisation improves the results above the sentence-length
normalisation alone. This contradicts the conclusion one can take from
the significant distance analysis, which says that the ratio
normalisation harms significance and is therefore less
successful. This is an instance of the noise/quality tradeoff,
however: ratio normalised features appear to listen more closely to
the data, at the expense of being interfered with by the noise there.
% wow that last sentence sucks. but you get the idea

\subsubsection{Self-Correlation}

It appears that a cosine is arriving at different results than the
other measures, though the correlation is still much higher than with
travel distance. A more precise investigation of this anomaly appears
below in section \ref{feature-ranking}.

\subsubsection{Correlation with Corpus Size}

The correlation of corpus size and dialect distance is a problem. It
is not a predicted as a side effect of the way dialect distance is
measured. The correlation of travel distance with corpus size makes
the situation murkier: the ratio-normalised distances correlate more
highly with travel distance than non-ratio-normalised distances, but
they also correlate more highly with corpus size. Is corpus size the
determining variable? Or is there an unknown variable influencing all
three? Some possibilities are ``interviewer boundaries'', common in
corpora collected by multiple people \cite{chambers98}, or perhaps the
interviewers got better over time and collected longer interviews as
they moved throughout the country,
or perhaps cultural differences between the interviewer and
interviewees caused some participants in one area to talk more than in
another area.

% TODO: It would be cool if this were *present work* instead
In any case it is possible that the fixed-size sampling method is not doing its
job in eliminating size differences between corpora. Future work
should develop a method for normalising a comparison between two full
corpora. It should avoid sampling, but also take the relative number
of sentences into account. It is not difficult to come up
with a simple method to do so, but it needs some checking to make sure
that the method is valid.

\subsection{Cluster Dendrograms}

The cluster dendrograms in chapter \ref{results-chapter} are dangerous
to interpret too closely on their own; the instability of a single
dendrogram means that small clusters cannot be analysed reliably. For
example, in figure \ref{cluster-r-trigram-freq}, a two-way split
between the regions on the top and bottom of the page is
obvious, and a three-way split is easy to argue for, but small
clusters like the first four sites (Fole, Skinnskatteberg, Faro and
Vaxtorp) are not likely to be found in that exact configuration in
other dendrograms.

It is safer to analyse the consensus trees; the smoothing effect of
taking the majority rule of each cluster will show where the optimal
cutoff for splitting clusters is. The consensus tree for
sentence-length normalisation has 5 main clusters, one of which has
two additional subclusters. Additionally, Viby and Bara don't cluster
with any other interview site.

In contrast, the consensus tree for ratio normalisation only has two
subtrees: Loderup/Bredsatra and Jamshog/Ossjo/Torsas. By this measure,
adding the ratio normalisation is less successful than leaving it out:
the variations over measure and feature set do not come to much of an
agreement, so there is less information available from the ratio
normalised consensus tree.

\begin{figure}
\begin{itemize}
\item S:t Anna
\item Sorunda
\end{itemize}
\caption{Red Cluster}
\label{red-cluster}
\end{figure}

\begin{figure}
\begin{itemize}
\item J\"amsh\"og
\item Tors\.as
\item \"Ossj\"o
\end{itemize}
\caption{Pink Cluster}
\label{pink-cluster}
\end{figure}

\begin{figure}
\begin{itemize}
\item Breds\"atra
\item K\"ola
\item L\"oderup
\end{itemize}
\caption{Brown Cluster}
\label{brown-cluster}
\end{figure}

\begin{figure}
\begin{itemize}
\item B\"oda
\item Frilles\.as
\item Norra R\"orum
\item Tors\"o
\item Villberga
\end{itemize}
\caption{Yellow Cluster}
\label{yellow-cluster}
\end{figure}

\begin{figure}
\begin{itemize}
\item Indal
\item Leksand
\end{itemize}
\caption{Green Cluster}
\label{green-cluster}
\end{figure}

\begin{figure}
\begin{itemize}
\item Bengtsfors
\item Floby
\item Segerstad
\end{itemize}
\caption{Cyan Cluster}
\label{cyan-cluster}
\end{figure}

\begin{figure}
\begin{itemize}
\item Ankarsrum
\item Anundsj\"o
\item Asby
\item F\.ar\"o
\item Fole
\item Orust
\item Skinnskatteberg
\item Sproge
\item V\.axtorp
\item \.Arsunda
\end{itemize}
\caption{Blue Cluster}
\label{blue-cluster}
\end{figure}

When these clusters are mapped onto the geography of Sweden, some
patterns are visible. The largest cluster, The blue-green cluster
forms a non-north non-metropolitan set. Specifically, the green
cluster is in the north, as are the blue and cyan cluster for the most
part. The Gotland interview sites also form part of the blue
cluster. However, the yellow cluster is interspersed through this
cluster and others. I see no obvious interpretation of it, despite the
fact that its five members clustered together in the majority of
dendrograms. The red cluster is easier to explain; since it is close
to Stockholm, it probably represents the metropolitan
dialect. Finally, the brown cluster appears to be only on the edge of
country, so perhaps its sites are remnants of an older dialect.

Most clear is the pink cluster containing J\"amshog, Tors\.as and
\"Ossj\"o. These three sites are clearly related both by dialect and
by geography. However, one item of note is that \"Ossj\"o is quite
different from its close neighbours V\"axtorp and Norra R\"orum. So
too is Tors\.as in a different cluster from the nearby Segerstad,
although that site is on an island.

I should probably spend time talking about the relation of these
findings to linguistics, unless I want to do that in a later
section. It looks like I will do it in multiple later sections, so
best to keep this short for now I guess.

\subsection{Composite Cluster Maps}

Composite cluster maps use a similar underlying technique as consensus
trees--cluster dendrograms, but combine and present the information in
a very different way. The result is much more like the traditional
isogloss boundaries of dialectology.

Both composite cluster maps, with and without the ratio normalisation,
support the north-to-south gradient held by dialectologists. (CITE:
The Nordic Languages). There are a number of horizontal boundaries
throughout Sweden, none of them particularly strong. The northernmost
boundary is somewhat thick in fact.

However, K\"ola and Frilles\.as still separate fairly well from their
neighbours.

Of all the boundaries, the one between Scania and the rest of Sweden
is the strongest. Due to the lack of interview sites in the middle of
south Sweden, the boundary is drawn further north than it
traditionally appears, but this is an effect of the software the
produced the figure. Notice that there is also a boundary between
J\"amshog, Tors\.as, and \"Ossjo\" and the other sites in
Scania. Their presence along the northern border of Scania is one
reason why its boundary with the rest of Sweden is so strong.

\subsection{MDS}

This shows very similar results to the hierarchical clustering. A
few strongly different regions appear in the south, there is a region
around Stockholm, and North Sweden (Norrland) groups together with a
couple of more southern regions outside the Stockholm region.

Things I noticed: cities, Scania distinction, sometimes shared with
Jamhog/Torsas/Ossjo, Stockholm/Uppsala/Malmo are nearly always
similar, northern sometimes looks different from central area. For
some reason Kola always patterns with the cities though \ldots But
Arsunda, right nearby, is always pretty different. Strange.

\subsection{Features}

Analysis of specific features

\subsection{Cosine}

What is up with cosine? Seriously.

\section{Compared to Previous Work}

In previous work on British English, this method failed to find
agreement between syntactic distance ($R$) and phonological distance
(Levenshtein) distance---there was no
significant correlation between the two methods. Although both showed
something like a North/South distinction in Britain, its orientation was much more
obvious from phonological distance. This lack of agreement was a
preliminary answer to the question of whether multiple
ways of measuring linguistic distance give the same results.

However, there were at least five reasonable explanations for the difference
between the two distance measures.
% First, and
% least satisfying, is the possibility that one of the distances is not
% measuring what it is supposed to. Second, the corpora may not agree
% because of the 40 year difference in age and differing collection
% methodologies. Third, syntactic and phonological dialect markers may
% not share the same boundaries.

\begin{enumerate}
\item One or both of the distances does not measure what it is supposed to.
\item The two corpora may not agree on dialect boundaries because of
  their 40-year difference in age.
\item Place of birth, as recorded in the ICE, may not correlate well
  with spoken dialect, especially given variations in speaker
  education level and place of residence.
\item Dialect boundaries may appear from systematic variation in
  annotation practices rather than the speech.
\item Syntactic and phonological dialect boundaries may be different.
\end{enumerate}

Of these, this dissertation addresses the second, third and fourth
problems directly by using a single corpus, Swedia2000, annotated by a single
person. (TODO: This may not be true for the phonological annotation.)
By finding significant distances between all interview sites of
Swedia2000, it also suggests that $R$ is measuring syntax
distance. PROBABLY.

The last is the most interesting because previous work will not have
exposed this difference. Traditional dialectometry focuses on a strong
agreement among a few features from each collection site. Because
syntactic features are fewer in number than phonological ones, they
are under-represented in this type of analysis. Unfortunately, this
means that the syntactic contribution to isogloss bundles is
correspondingly reduced. In addition, because of isogloss bundles'
insensitivity to rare variations, syntactic features rarely contribute
to isogloss bundles of successful dialect boundaries.
% I really need to CITE this.

In contrast, computational analysis, such as \cite{shackleton07},
captures feature variation precisely using statistical analysis and
sophisticated algorithms. The resulting analysis displays dialects as
gradient phenomena, displaying much more complexity than the
corresponding isogloss analysis. But current specialized computational
methods only apply to phonology. Syntactic data cannot be analyzed
without a syntax-specific method.

This paper attempts to address that lack, and provide some first steps
to show whether syntax and phonology assist each other in establishing
dialects, or whether their dialect regions are unrelated. If they are not
related, and syntactic gradients can be as weak as phonological ones,
then some new dialect regions may become apparent that were not visible in
previous phonology-only analyses.

\subsection{Improvements on British Dialect Experiment}

This dissertation improves on the British experiment in a number of
ways. It addresses the obvious criticism that syntax distance on the
ICE requires so much data that the results are no more informative
syntax those of traditional dialectology---its precision lags
phonological distance methods badly. However, $R$ works with much
smaller corpora when run on Swedia2000. This shows that the problem
with the British experiment is not the distance method, but the
corpus, which fails to capture dialect differences. Most likely is
that the interviewees, mostly in a college setting, actively tried to
suppress dialect differences during the interview.

Another problem with the current study is the 40-year difference in
collection dates between the phonological corpus and the syntactic
corpus. A recent phonological corpus would likely show the same sort
of changes in the North/South divide that show up in the syntactic
corpus. The British population became more mobile during the second
half of the 20th century, and the SED survey explicitly attempted to capture
the dialects that existed before this happened \cite{orton78}.
It would also be nice to have data from the rest of the United Kingdom for
comparison as well, or at least Scotland and Wales as with the ICE.


% TODO: integrate this.
% Alternatively, I could just look at the region pairs that fail to
% achieve significance in the syntactic permutation test and check to
% see if their phonological distance is lower than the other pairs. I
% don't do this (yet).

One interesting question is
how phonological and syntactic distances correlate with geographic
distance---\namecite{gooskens04a} shows that often the correlation is
very good. This would also allow better visualization of dialect areas
than a hierarchical dendrogram.

\section{Future Work}

Try all those smarter variants of $R$.

Include the rest of Nodalida once it is done.

Better normalisation and feature ranking are needed. It appears that
the current normalisations vary either in favouring differences
only in high-frequency features OR in favouring rare features so much
that the most important appear to be those that only occur in one of
the two regions.

\section{The End}

This dissertation contributes a better understanding of syntax with
respect to dialectometry. It establishes that statistical methods can
find interesting things, and with not much more data than is expected
of previous dialectometry in other areas. Remember, the majoriy of
interviews used here were less than 1000 sentences. Previous work
pointed the way (Nerbonne \& Wiersma (2006) and Sanders (2008)) but
failed to establish the utility and reliability of these methods
either by lack of dialect application or by lack of consistent
results. This dissertation addresses these shortcomings
comprehensively.

In addition, it points the way toward future work in Swedish; while
the results here are interesting, it is difficult to corraborate them
solidly because of the lack of study on Swedish dialects, both in
dialectology and dialectometry. This gap in the literature is on its
way to being remedied with the work of Leinonen in dialectometry and
X,Y,Z in dialectology.

Like its findings, future directions based on this work are
twofold. In general dialectometry, syntactic investigations should
begin, hopefully extending to languages for which the syntactic
variation is already well-studied.

In Swedish, I hope that this investigation of syntactic dialect
variation will lead to further work in this area; there is little
enough right now, and perhaps a computer-generated overview of the
interesting features will spark some new avenues of investigation for
linguists.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "dissertation.tex"
%%% End: 
