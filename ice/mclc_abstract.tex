\documentclass[11pt,letterpaper]{article}
\pdfpagewidth=\paperwidth
\pdfpageheight=\paperheight
\usepackage{times}
\usepackage{acl07}
\begin{document}
\title{Comparison of Phonological and Syntactic Distance Measures}

\maketitle

This project compares phonology and syntax distances in dialectometry,
using computational methods as a basis. It is an extension of
previous work by \cite{nerbonne06} and
\cite{sanders07} in the relatively new area of syntax
distance. The purpose of this work is to integrate phonological and
syntactic data in the way that early dialectology did, but using the
computational methods that have previously only been used to analyze
one area of linguistics at a time.

To do this, I measured phonological distance using the Survey of
English Dialects (SED) \cite{orton63} interview data for phonology,
and the International Corpus of English Great Britain (ICE-GB) \cite{nelson02} speech
data for syntax. I used Levenshtein distance \cite{lev65} with
phonological features \cite{nerbonne97} for phonological distance, and
a permutation test based on Kessler's $R$ \cite{kessler01} for
syntactic distance. I measured the two distances between
the nine Government Office Regions of England and compared the
correlation and clustering of the results.

The comparison shows how phonology and syntax contribute to dialect
boundaries, and whether these boundaries reinforce each other. In
addition, new dialect areas may be discernible in the syntactic
distance results; this is the first computational syntactic
analysis of British English dialects, to my knowledge.

\section{Methods}
\subsection{Phonological Distance}
Levenshtein distance, also known as string edit distance, is a dynamic
programming method that counts the number of changes between two
strings. In addition, Levenshtein distance can be extended to
calculate featural differences; that is, to use subsegmental
differences to give differing distances between individual segments
\cite{heeringa04}. For this, I used the feature set that
\newcite{shackleton07} designed for his phonological analysis of the
SED. I continued with a simplified version of his experiment, using
the same 55-word subset of the SED; however, I did not replicate any of
the extensive statistical analysis of his experiment.

\subsection{Syntactic Distance}
Syntax distance was calculated using the method of
\newcite{nerbonne06}. They used a simple measure of distance,
$R$, introduced by \newcite{kessler01}. On its own, $R$ may give
incorrect results because of differences in corpus size and average
sentence length; Nerbonne \& Wiersma normalize $R$ to account for
these differences. Then a permutation test is run to determine whether the
normalized $R$ is significant.

The permutation test repeatedly compares the original $R$ between the
two corpora with the $R$ between a shuffled split of the two
corpora. Shuffling the corpora should destroy any differences between the
two, so the $R$ of the shuffled split should be lower than the
original. If this is the case 95\% of the time, the original $R$ is
statistically significant for $p < 0.05$.

Nerbonne \& Wiersma use trigrams to capture syntactic structure, while
\newcite{sanders07} also uses leaf-ancestor
paths. Leaf-ancestor paths were designed by
\newcite{sampson00} for parser evaluation: they
consist of the path of nodes from each leaf up to the root of the
sentence. For example,
N-NP-VP-S might be the leaf-ancestor path of the subject of a
sentence, while N-NP-PP-VP-S might be the object of a preposition.

\section{Experiment}

The permutation test over $R$ for syntactic distance requires fairly
large data sets. In order to create these data sets, the ICE-GB was
divided into nine sub-corpora corresponding to the English Government
Office Regions \cite{nelson02}. The Survey of English Dialects (SED)
provided phonological data and was divided into the same nine
sub-corpora \cite{orton63}. The 55-word subset of the SED developed by
Shackleton was used in order to focus on variation known to occur in
England.

Two fully connected graphs of the nine English regions were created,
the first with edges containing information
from the permutation test over $R$, and the second with edges containing
Levenshtein distance. Each graph was analyzed by clustering it
hierarchically; the edge distances of the two graphs were also
checked for statistically significant correlation.

\section{Results}
Clustering phonological distance produces a clear North/South division, replicating
previous linguistic analyses. Sub-clusters, such as that of London, the
South and East England, are also consistent with existing linguistic
knowledge. In contrast, the result of clustering syntactic distance is not so clear; a
North/South distinction appears here too, but with some unexpected
differences; for example, the
Northwest region clusters with the Southwest region. More importantly,
there is no significant correlation between the inter-region
phonological distances and syntactic distances.

There are several possible reasons for this lack of correlation. The
two distance measures may find different dialect boundaries based on
differences between syntax and phonology. Dialect boundaries may have
shifted during the 40 years between the collection of the SED and the
collection of the ICE-GB. One or both methods may be measuring the
wrong thing. Further work is needed, both with British English and
with other corpora, to resolve these questions and improve our
understanding of syntax distance with respect to other methods of
dialectometry.

\bibliographystyle{acl}
\bibliography{central}
\end{document}
