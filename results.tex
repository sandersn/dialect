\chapter{Results}
\label{results-chapter}
% TODO: Many tables are ugly
% TODO: Re-order features in order of importance in all tables
% eg unigram last, preceded by deparc, timbl-dep (redep), etc

These results are meant to answer two main questions: first, how well does
this approach to syntactic dialectometry agree with dialectology?
Second, what combinations of distance measures, feature
sets and other settings produce the best results for linguistic
analyses? Additionally, the results are meant to allow comparison with
phonological dialectometry.

The organization of this chapter mirrors the order of the methods
chapter, particularly the output analysis (section
\ref{output-analysis}). First, there is an overview of the different
parameter settings, the combinations of distance measure and feature
set, as well as other settings. Then the number of significant
distances for each parameter setting is given, which is followed by
the correlation with geography and travel distance for each parameter
setting. These sections focus mainly on detecting which settings do not
produce valid results, so that they can be ignored in the rest of the
chapter. At a high level, they answer the question of the suitability
of statistical syntactic dialectometry: whether or not significant
results can be found.

Next, the specific dialectological results are examined. First,
cluster dendrograms provide a visualization of which regions the
distance measures find to be similar. In addition, to improve the
reliability of the dendrograms, consensus trees and composite cluster
maps are produced. Next, multi-dimensional scaling gives an smoother
view of similarity than clusters. Finally, features are ranked and
extracted from each cluster in the consensus tree.

\section{Parameter Settings}

There are 180 parameter settings investigated in this chapter. This
number arises from the four parameters: measure, feature set, sampling
method and number of normalization iterations. 5 measures, 9 feature
sets, 2 sampling methods and 2 numbers of normalization iterations
gives $5\times 9 \times 2 \times 2=180$ different settings. The
settings are given in table \ref{parameter-settings}.

\begin{table}
\begin{tabular}{|c|} \hline
  Feature Set \\\hline
  Leaf-Ancestor Path \\
  Part-of-speech Trigram \\
  Leaf-Head Path \\
  Phrase Structure Rule \\
  PSR with Grandparent \\
  Part-of-speech Unigram \\
  Leaf-Head Path, based on Timbl training \\
  Leaf-Arc Path \\
  All features combined \\ \hline
\end{tabular}
\begin{tabular}{|c|} \hline
  Measure \\ \hline
  $R$ \\
  $R^2$ \\
  Kullback-Leibler divergence \\
  Jensen-Shannon divergence \\
  cosine dissimilarity\\\hline \hline
  Sampling Method \\ \hline
  1000 sentences \\
  All sentences \\ \hline \hline
  Iterations of normalization \\ \hline
  1 \\
  5 \\ \hline
\end{tabular}
\caption{Settings for the five parameters tested}
\label{parameter-settings}
\end{table}
% Actually, all this should probably go in methods too, somewhere as a summary.

In addition, the size of each of the 30 interview sites are given in
table \ref{corpus-size}.

\begin{table}
\begin{tabular}{c|cc|c|cc}
      Site & Sentences & Words & Site & Sentences & Words \\\hline
     Ankarsrum &  630 &  7708 & Leksand &  923 &   10676\\
    Anundsjo &  1144 &   11897 &  Loderup &  429 &   7850\\
    Arsunda &  937 &   8933 & Norra Rorum &  546 &  9160\\
     Asby &  693 &   7171 & Orust &  1067 &   11409\\
     Bara &  696 &   10724 & Ossjo &  481 &   12275\\
     Bengtsfors &  663 &   7423 & Segerstad &  837 &   9746\\
    Boda &  1029 &   17425 &  Skinnskatteberg &  730 &   9529\\
     Bredsatra &  360 &   6938 & Sorunda &  768 &   11144\\
     Faro &  659 &   8260 & Sproge &  381 &   4399\\
     Floby &  557 &   6392 & StAnna &  876 &   13156\\
     Fole &  727 &   9920 & Tors\.as &  374 &   9217\\
     Frillesas &  572 &   9634 & Torso &  956 &   15577\\
    Indal &  1126 &   13090 &  Vaxtorp &  903 &   11353\\
     Jamshog &  301 &   8661 & Viby &  431 &   6734\\
     K\"ola &  528 &   10133 & Villberga &  680 &   11479\\
\end{tabular}
  \caption{Corpus Size of Interview Sites}
  \label{corpus-size}
\end{table}

\section{Significant Distances}

Significant distances help answer the question whether a syntactic
measure has succeeded in finding reliable distances. The measures
should have zero non-significant distances, or at least a small
number. In the tables, the total number of comparisons between all 30
regions is the $435=30(30-1) / 2$. In the first set,
tables \ref{sig-1-1000} -- \ref{sig-1-full}, the results are shown
from one iteration of the normalization step. In the second set,
tables \ref{sig-5-1000} -- \ref{sig-5-full}, the results
from five normalization iterations are shown.

Bold numbers in the tables indicate that more than 5\% of the
distances were not significant. In table \ref{sig-5-full}, the
5-iteration table that compares full corpora, the only combination
with {\it less} than 5\% non-significant results is cosine
dissimilarity with unigram features, marked with italics. Note that
here, 5\% is an arbitrary cutoff point not related to the usual
significance cutoff $p < 0.05$; the basis for these tables are
themselves number of significant distances found.

\begin{table}
\begin{tabular}{l|rrrrr}
  & $R$ & $R^2$ & KL & JS & cos  \\ \hline
  Leaf-Ancestor &0&0&11&0&0 \\
  Trigram &0&0&0&0&0 \\
  Leaf-Head &0&0&0&0&0 \\
  Phrase-Structure Rules &0&0&\textbf{95}&0&0 \\
  Phrase-Structure with Grandparents &0&0&\textbf{273}&0&0 \\
  Unigram &0&0&0&0&0 \\
  Leaf-Head with MaltParser trained by Timbl &0&0&\textbf{47}&0&0 \\
  Leaf-Arc Labels&0&0&0&0&0 \\
  All Features Combined &0&0&0&0&0 \\
\end{tabular}
\caption{Number of significant distances for sample size 1000, 1
  normalization}
\label{sig-1-1000}
\end{table}

\begin{table}
\begin{tabular}{l|rrrrr}
& $R$ & $R^2$ & KL & JS & cos  \\ \hline
  Leaf-Ancestor&7&11&12&\textbf{35}&9 \\
  Trigram&4&1&0&\textbf{24}&1 \\
  Leaf-Head&10&12&20&\textbf{44}&19 \\
  Phrase-Structure Rules&\textbf{26}&17&\textbf{24}&\textbf{49}&20 \\
  Phrase-Structure with Grandparents&\textbf{58}&\textbf{35}&\textbf{38}&\textbf{71}&\textbf{33}
   \\
  Unigram&1&2&0&0&2 \\
  Leaf-Head with MaltParser trained by Timbl&11&21&18&\textbf{74}&\textbf{30}
   \\
  Leaf-Arc Labels&14&19&\textbf{37}&\textbf{94}&17 \\
  All Features Combined&0&0&1&8&2 \\
\end{tabular}
 \caption{Number of significant distances for complete regions, 1
   normalization}
 \label{sig-1-full}
\end{table}

\begin{table}
\begin{tabular}{l|rrrrr}
& $R$ & $R^2$ & KL & JS & cos  \\ \hline
  Leaf-Ancestor&5 & \textbf{56} & \textbf{34} & 0 & 0\\
  Trigram&3 & 2 & 0 & 0 & 0\\
  Leaf-Head&3 & 14 & 4 & 0 & 0\\
  Phrase-Structure Rules&11 & 4 & \textbf{66} & 1 & 0\\
  Phrase-Structure with Grandparents&18 & 0 & \textbf{109} & 4 & 0\\
  Unigram&\textbf{52} & \textbf{53} & 15 & 17 & 0\\
  Leaf-Head with MaltParser trained by Timbl&7 & 20 & \textbf{45} & 0 & 0\\
  Leaf-Arc Labels&6 & \textbf{54} & 17 & 1 & 0\\
  All Features Combined&0 & 4 & 0 & 0 & 0\\
\end{tabular}
\caption{Number of significant distances for sample size 1000, 5
  normalizations}
\label{sig-5-1000}
\end{table}
\begin{table}
\begin{tabular}{l|rrrrr}
& $R$ & $R^2$ & KL & JS & cos  \\ \hline
  Leaf-Ancestor&\textbf{290} & \textbf{284} & \textbf{287} & \textbf{278} & \textbf{204}\\
  Trigram&\textbf{284} & \textbf{283} & \textbf{283} & \textbf{276} & \textbf{196}\\
  Leaf-Head&\textbf{293} & \textbf{286} & \textbf{285} & \textbf{279} & \textbf{211}\\
  Phrase-Structure Rules&\textbf{289} & \textbf{294} & \textbf{286} & \textbf{275} & \textbf{236}\\
  Phrase-Structure with Grandparents&\textbf{285} & \textbf{290} & \textbf{286} & \textbf{270} & \textbf{258}\\
  Unigram&\textbf{297} & \textbf{296} & \textbf{294} & \textbf{293} &
  \textit{9}\\
  Leaf-Head with MaltParser trained by Timbl&\textbf{294} & \textbf{289} & \textbf{288} & \textbf{284} & \textbf{222}\\
  Leaf-Arc Labels&\textbf{294} & \textbf{290} & \textbf{291} & \textbf{293} & \textbf{162}\\
  All Features Combined&\textbf{279} & \textbf{279} & \textbf{279} & \textbf{269} & \textbf{191}\\
\end{tabular}
 \caption{Number of significant distances for complete regions, 5
   normalizations}
 \label{sig-5-full}
\end{table}

% TODO: Need to add references to diagrams and also any
% citations

Analysis of the significance of dialect distance provides a measure of
how reliable the distances to be analyzed later in this chapter are. A
distance that does not find significant distances between of 30
regions is not suitable for precise inspection, although small numbers
of non-significant distances will still allow methods to
return interpretable results.

The highest number of significant distances are found in the first
case (figure \ref{sig-1-1000}): 1 round of normalization with a
fixed-size sample of 1000 sentences. From there, both full-corpus
comparisons (figure \ref{sig-1-full}) and 5 rounds of normalization
(figure \ref{sig-5-1000}) have fewer significant distances, although
the number is still usable. However, the combination of the two, with
5 rounds of normalization over full-corpus comparisons, has only one
combination with fewer than 5\% of distances that are {\it not}
significant. Although both full-corpus comparisons and multiple rounds
of normalization may increase the precision of the results, their
combined effect on significance is so detrimental that its results are
useless. For the rest of the analysis, the combination of full-corpus
comparison and 5 rounds of normalization will be skipped.

\subsubsection{Significance by Measure}

The distance measures most likely to find significance are, in order,
cosine dissimilarity, Jensen-Shannon divergence and $R$. Each method
had different parameter settings for which it was stronger. For
1000-sentence sampling, cosine similarity resulted in all significant
distances, even for part-of-speech unigrams, which are intended as the
baseline feature set. Excluding unigrams, Jensen-Shannon divergence
has similar performance. For full-corpus comparisons, both perform
considerably worse; surprisingly, both perform better on unigram
features, Jensen-Shannon so much so that it's the only feature set for
which it finds all significant distances. $R$, on the other hand,
performs decently on all combinations of parameter settings; its low
significance for phrase structure rules is shared by Kullback-Leibler
and Jensen-Shannon divergences.
% TODO : Maybe more on cosine later. Maybe not.

When comparing the performance of Kullback-Leibler and Jensen-Shannon
divergence it is not surprising that Jensen-Shannon outperforms
Kullback-Leibler on fixed-size sampling. Although both are called
``divergence'', Jensen-Shannon divergence is actually a
dissimilarity. Recall that the divergence from point A to B may differ
from the divergence from point B to A. A divergence like
Kullback-Leibler can be converted to a dissimilarity by measuring
$KL(A,B) + KL(B,A)$. However, this dissimilarity must skip features
unique to a single corpus in order to avoid division by zero. This
means that for smaller corpora Kullback-Leibler loses information that
Jensen-Shannon is able to use.  On the other hand, while this may
explain Kullback-Leibler's improved performance for full-corpus
comparisons, it doesn't explain Jensen-Shannon's much worse
performance.

\subsubsection{Significance by Feature Set}

% \item Unigrams do form an adequate baseline; they are bad but not too
%   bad.

% The feature sets most likely to find significance are the combined
% features and unigrams., in order,
% trigrams, all combined features and leaf-head paths (both with
% support-vector-machine training and with Timbl's instance-based
% training). Without ratio normalization, the other feature sets are not
% much worse, but with it included, these three are the best by some
% distance.

For 1 round of normalization, the best feature sets are the simple
ones: trigrams and unigrams, as well all combined features. On the
other hand, trigrams and leaf-head paths (with its variations) are the
best feature sets with 5 rounds of normalization. However, the
variation isn't strong; any feature set can give good results with the
right distance measure. The problem is that no clear patterns emerge.

The relatively high quality of trigrams and unigrams does not make
sense given only the linguistic facts; however, it is likely that the
entirely automatic annotation used here introduces more and more
errors as more annotators run, operating on previous automatic
annotations. Trigrams are the result of only one automatic annotation,
and one for which the state of the art is near human performance. So
the fact that these particular parts of speech are of higher quality
than the corresponding dependencies or constituencies is probably the
deciding factor in their higher number of significant
distances.

% Although it is impossible to tell from my results, I
% predict that a manually annotated dialect corpus would show that
% non-flat syntactic structure is helpful in producing significant
% distances.

Given the above facts, the question should rather be: why do leaf-head
paths perform as well as they do? Better, for example, than the
leaf-ancestor paths on which they're modeled: why does more
normalization hurt leaf-ancestor paths but not leaf-head paths?  It
could be that there is less room for error; many of the common
leaf-head paths are short: short interview sentences with simple
structure make for shorter leaf-head paths than leaf-ancestor
paths. As a result, the important leaf-head paths consist mainly of a
couple of parts-of-speech.

Another reason could be a difference in parsers: MaltParser has been
tested before with Swedish (CITE). Besides English, the Berkeley
parser has been tested prominently on German and Chinese. Therefore,
the difference would better be explained by appealing to the
difference in parsers rather than an unsuitability of Swedish for
constituent analysis.

It is disappointing linguistically that trigrams provide the most
reliable results so far; a linguist would expect that including
syntactic information would make it easier to measure the differences
between regions. If it is, as hypothesized here, an effect of chaining
machine annotators, a study using manually annotated corpora could
detect this. However, it still means that trigrams are the most useful
feature set from a practical view, because automatic trigram tagging
is very close to human performance with little training. That means
the only required human work is the transcription of interviews in
most cases.

On the other hand, if additional features sets are to be developed for
a corpus, then combining all available features seems to be a
successful strategy. The distance measures seem to be able to use all
available information for finding significant distances.


\section{Correlation}

In dialectology, the default expectation for dialect distance is that
it correlates with geographic distance \cite{chambers98}. A lack of
correlation does not necessarily mean that a measure is useless, but
presence of correlation means that the distance measure substantiates the
well-known tendency of dialect distributions to be more or less
smoothly gradient over physical space.

In addition, distance measures are more likely to correlate
significantly with travel distance than with straight-line geographic
distance. This makes sense since the difficulty of moving from place
to place is what influences dialect formation, and taking roads into
account is an improved estimate over straight-line distance.

The tables that present geographic and table correlation,
\ref{cor-1-1000} -- \ref{travel-cor-5-full}, mark significant
correlations with a star for $p < 0.05$, two stars for $p < 0.01$ and
three stars for $p < 0.001$. However, these correlations are only
trustworthy in the case that the underlying distances are
significant. Significant correlations from significant distances (as
cross-referenced from tables \ref{sig-1-1000} -- \ref{sig-5-full}) are
marked by italics.

Besides this, correlation between combinations of measure/feature set
can show how closely related they are--in other words, how similarly
they view the underlying data which remains the same for all.

This is similar to the reasoning behind correlation with
geography---but the assumption is that geography is a factor
underlying dialect formation; while the distance measure measures some
aspect of the language which we hope is dialects, it is indirectly
(even less directly) measuring the geography. Therefore, correlation
with geography should occur.

Third, correlation with corpus size is not predicted and is probably
an undesired defect in sampling or normalization. Correlation with
corpus size is presented in tables \ref{size-cor-1-1000} --
\ref{size-cor-5-full}.

\begin{table}
\begin{tabular}{l|rrrrr}
& $R$ & $R^2$ & KL & JS & cos  \\ \hline
  Leaf-Ancestor&-0.01 & 0.03 & 0.02 & -0.02 & 0.08\\
  Trigram&0.17 & 0.17 & 0.10 & 0.19 & 0.13\\
  Dependency&-0.06 & 0.03 & 0.00 & -0.07 & 0.05\\
  Phrase-Structure Rules&0.01 & \textit{0.18*} & 0.16 & 0.01 & 0.12\\
  Phrase-Structure with Grandparents&0.03 & \textit{0.25*} & 0.21* & 0.03 & 0.12\\
  Unigram&\textit{0.18*} & 0.17 & \textit{0.29**} & \textit{0.30**} & \textit{0.18*}\\
  Dependencies, MaltParser trained by Timbl&-0.07 & 0.02 & -0.00 & -0.08 & 0.05\\
  Dependency, Arc Labels&-0.07 & 0.06 & -0.06 & -0.09 & 0.00\\
  All Features Combined&-0.02 & 0.03 & 0.01 & -0.02 & 0.07\\
\end{tabular}
 \caption{Geographic correlation for sample size 1000, 1 normalization iteration}
 \label{cor-1-1000}
\end{table}

\begin{table}
\begin{tabular}{l|rrrrr}
& $R$ & $R^2$ & KL & JS & cos  \\ \hline
  Leaf-Ancestor&0.02 & 0.09 & 0.11 & -0.00 & 0.09\\
  Trigram&\textit{0.27*} & \textit{0.26*} & \textit{0.30**} & 0.21* & 0.08\\
  Dependency&-0.03 & 0.12 & 0.14 & -0.06 & 0.02\\
  Phrase-Structure Rules&0.13 & \textit{0.36**} & 0.30** & 0.11 & \textit{0.20*}\\
  Phrase-Structure with Grandparents&0.15 & 0.41** & 0.36** & 0.14 & 0.19*\\
  Unigram&\textit{0.20*} & \textit{0.20*} & \textit{0.33**} & \textit{0.33**} & \textit{0.22*}\\
  Dependencies, MaltParser trained by Timbl&-0.02 & 0.14 & 0.16 & -0.05 & 0.02\\
  Dependency, Arc Labels&-0.06 & 0.13 & -0.01 & -0.12 & -0.03\\
  All Features Combined&0.03 & 0.11 & 0.16 & -0.00 & 0.04\\
\end{tabular}
 \caption{Geographic correlation for complete corpora, 1 normalization iteration}
 \label{cor-1-full}
\end{table}

\begin{table}
\begin{tabular}{l|rrrrr}
& $R$ & $R^2$ & KL & JS & cos  \\ \hline
  Leaf-Ancestor&0.14 & 0.14 & 0.16 & 0.15 & 0.08\\
  Trigram&\textit{0.22*} & 0.17 & \textit{0.22*} & \textit{0.22*} & 0.16\\
  Dependency&0.10 & 0.11 & 0.15 & 0.12 & 0.10\\
  Phrase-Structure Rules&0.14 & 0.10 & 0.14 & 0.15 & 0.06\\
  Phrase-Structure with Grandparents&0.16 & 0.14 & 0.14 & 0.15 & 0.05\\
  Unigram&0.12 & 0.11 & 0.14 & 0.13 & 0.17\\
  Dependencies, MaltParser trained by Timbl&0.09 & 0.12 & 0.16 & 0.11 & 0.11\\
  Dependency, Arc Labels&0.08 & 0.10 & 0.14 & 0.10 & 0.09\\
  All Features Combined&0.19 & 0.16 & \textit{0.20*} & \textit{0.21*} & 0.11\\
\end{tabular}
 \caption{Geographic correlation for sample size 1000, 5
   normalizations}
 \label{cor-5-1000}
\end{table}

\begin{table}
\begin{tabular}{l|rrrrr}
& $R$ & $R^2$ & KL & JS & cos  \\ \hline
  Leaf-Ancestor&-0.14 & -0.16 & -0.15 & -0.15 & -0.08\\
  Trigram&-0.09 & -0.07 & -0.09 & -0.09 & -0.09\\
  Dependency&-0.22 & -0.21 & -0.18 & -0.22 & -0.10\\
  Phrase-Structure Rules&-0.19 & -0.14 & -0.11 & -0.20 & -0.01\\
  Phrase-Structure with Grandparents&-0.17 & -0.11 & -0.09 & -0.18 & -0.02\\
  Unigram&-0.10 & -0.06 & -0.07 & -0.08 & 0.14\\
  Dependencies, MaltParser trained by Timbl&-0.19 & -0.18 & -0.18 & -0.19 & -0.10\\
  Dependency, Arc Labels&-0.21 & -0.18 & -0.18 & -0.21 & -0.10\\
  All Features Combined&-0.18 & -0.18 & -0.16 & -0.18 & -0.09\\
\end{tabular}
 \caption{Geographic correlation for complete corpora, 5 normalizations}
 \label{cor-5-full}
\end{table}

\begin{table}
\begin{tabular}{l|rrrrr}
& $R$ & $R^2$ & KL & JS & cos  \\ \hline
  Leaf-Ancestor&-0.03 & 0.02 & 0.01 & -0.04 & 0.07\\
  Trigram&0.20 & 0.19 & 0.11 & \textit{0.23*} & 0.14\\
  Dependency&-0.07 & 0.01 & -0.01 & -0.08 & 0.05\\
  Phrase-Structure Rules&0.01 & \textit{0.18*} & 0.17 & 0.00 & 0.14\\
  Phrase-Structure with Grandparents&0.03 & \textit{0.26*} & 0.22* & 0.03 & 0.15\\
  Unigram&\textit{0.20*} & \textit{0.19*} & \textit{0.30**} & \textit{0.31**} & \textit{0.21*}\\
  Dependencies, MaltParser trained by Timbl&-0.08 & 0.02 & -0.01 & -0.09 & 0.05\\
  Dependency, Arc Labels&-0.08 & 0.05 & -0.06 & -0.10 & 0.00\\
  All Features Combined&-0.03 & 0.03 & 0.01 & -0.03 & 0.06\\
\end{tabular}
 \caption{Travel correlation for sample size 1000, 1 normalization iteration}
 \label{travel-cor-1-1000}
\end{table}

\begin{table}
\begin{tabular}{l|rrrrr}
& $R$ & $R^2$ & KL & JS & cos  \\ \hline
  Leaf-Ancestor&0.02 & 0.08 & 0.11 & 0.00 & 0.08\\
  Trigram&\textit{0.31*} & \textit{0.28*} & \textit{0.32**} & 0.26* & 0.09\\
  Dependency&-0.02 & 0.12 & 0.13 & -0.05 & 0.01\\
  Phrase-Structure Rules&0.15 & \textit{0.37**} & 0.32** & 0.13 & \textit{0.22*}\\
  Phrase-Structure with Grandparents&0.17 & 0.43** & 0.38** & 0.16 & 0.22*\\
  Unigram&\textit{0.22*} & \textit{0.22*} & \textit{0.33**} & \textit{0.34**} & \textit{0.24*}\\
  Dependencies, MaltParser trained by Timbl&-0.01 & 0.14 & 0.17 & -0.04 & 0.02\\
  Dependency, Arc Labels&-0.06 & 0.12 & -0.02 & -0.12 & -0.03\\
  All Features Combined&0.04 & 0.10 & 0.16 & 0.01 & 0.04\\
\end{tabular}
 \caption{Travel correlation for complete corpora, 1 normalization iteration}
 \label{travel-cor-1-full}
\end{table}

\begin{table}
\begin{tabular}{l|rrrrr}
& $R$ & $R^2$ & KL & JS & cos  \\ \hline
  Leaf-Ancestor&0.17 & 0.19* & 0.17* & 0.18 & 0.07\\
  Trigram&\textit{0.24*} & \textit{0.20*} & \textit{0.25*} & \textit{0.26*} & 0.16\\
  Dependency&0.14 & 0.16 & 0.17 & 0.15 & 0.10\\
  Phrase-Structure Rules&0.17 & 0.14 & 0.16* & 0.18 & 0.06\\
  Phrase-Structure with Grandparents&0.19 & \textit{0.18*} & 0.17* & 0.19 & 0.06\\
  Unigram&0.15 & 0.13 & \textit{0.17*} & 0.16 & \textit{0.20*}\\
  Dependencies, MaltParser trained by Timbl&0.12 & 0.16 & 0.18 & 0.14 & 0.11\\
  Dependency, Arc Labels&0.09 & 0.13 & 0.14 & 0.11 & 0.08\\
  All Features Combined&\textit{0.23*} & \textit{0.20*} & \textit{0.22*} & \textit{0.24*} & 0.11\\
\end{tabular}
 \caption{Travel correlation for sample size 1000, 5 normalizations}
 \label{travel-cor-5-1000}
\end{table}

\begin{table}
\begin{tabular}{l|rrrrr}
& $R$ & $R^2$ & KL & JS & cos  \\ \hline
  Leaf-Ancestor&-0.13 & -0.13 & -0.10 & -0.13 & -0.04\\
  Trigram&-0.06 & -0.04 & -0.05 & -0.06 & -0.05\\
  Dependency&-0.20 & -0.17 & -0.13 & -0.19 & -0.06\\
  Phrase-Structure Rules&-0.15 & -0.08 & -0.05 & -0.15 & 0.04\\
  Phrase-Structure with Grandparents&-0.12 & -0.05 & -0.03 & -0.13 & 0.03\\
  Unigram&-0.07 & -0.03 & -0.04 & -0.05 & \textit{0.18*}\\
  Dependencies, MaltParser trained by Timbl&-0.18 & -0.15 & -0.12 & -0.18 & -0.05\\
  Dependency, Arc Labels&-0.20 & -0.17 & -0.14 & -0.19 & -0.06\\
  All Features Combined&-0.16 & -0.14 & -0.11 & -0.15 & -0.05\\
\end{tabular}
 \caption{Travel correlation for complete corpora, 5 normalizations}
 \label{travel-cor-5-full}
\end{table}

From the tables we see that parameter settings that correlate
significantly do so at rates around 0.2 to 0.3, with a high of 0.37
for phrase-structure-rule features measured by $R^2$, 1 normalization
iteration and comparison of full corpora.  The significant
correlations are mostly concentrated in the trigram, unigram and
combined feature sets.

\subsection{Analysis}

As with the number of significant distances, trigrams and unigrams are
the most likely to to correlate with geographic and travel distance,
as well as the combined feature set for the 5-normalization parameter
setting.
% As before, a possible explanation is that unigrams are
% simpler, so the type count is a higher than for other measures. With
% more rounds of normalization, more correlations shift over to
% trigrams.
Note that in figures \ref{cor-1-1000} --
\ref{travel-cor-5-full}, the significant correlations are marked with
an asterisk, but only the italicized correlations are based on at
least 95\% significant distances. For example, this means that most of
the significant correlations based on phrase-structure rules are not valid.

It is worthwhile to note, however, that the valid and significant
correlations based on phrase-structure grammars give the highest
correlations: 0.37 for $R^2$ with full-corpus comparisons and 1 round
of normalization.
The addition of more data and more normalization is interesting in
expanding the correlating parameter settings beyond those that include
unigram features. It may be that this is an instance of the noise/quality tradeoff.
These additions appear to extract more detail from
the data, at the cost of additional interference from noisy data.

% Goes here: Fevered speculation about why travel correlation is *better* with
% the methods that correlate *less*, for 1-full at least.
% OK never mind this isn't true.

\subsection{Inter-measure Correlation}

Correlation between measures simply indicates that they are using
similar information from the corpus to do their classification. This
is expected since most measures are quite similar. The one that
differs the most, cosine similarity, also correlates the least with
the others. The average correlation between different measures is
given in table \ref{self-correlation-measures}. The correlations are
averaged over the correlations for all combinations of feature set
with 1000-sentence samples and with non-significant correlations
removed before averaging.

\begin{table}
  \begin{tabular}{r|cccc}
 & $R^2$ & $KL$ & $JS$ & cos \\ \hline
  $R$ & 0.85 & 0.85 & 0.98 & 0.39\\
  $R^2$&& 0.90 & 0.83 & 0.57\\
  $KL$ &&& 0.88 & 0.67\\
  $JS$ &&&& 0.44
\end{tabular}
\caption{Average Inter-measure-correlation of measures}
 \label{self-correlation-measures}
\end{table}

The inter-measure correlation mostly says what is visible from the
significance testing and correlations. $R$ and Jensen-Shannon produce
nearly identical results, and correlate highly. Cosine similarity is
quite different from the other measures, though the correlation is
still higher than with travel distance. This makes some sense in that
the cosine at the heart of cosine similarity differs more from the
sums of absolute values and logarithms of other measures.

\subsection{Correlation with Corpus Size}

As previously stated, correlation with corpus size is not predicted and is probably
an undesired defect in sampling or normalization. Correlation with
corpus size is presented in tables \ref{size-cor-1-1000} --
\ref{size-cor-5-full}.

Corpus size between two regions can be measured in two different ways:
either by the sum of the regions' sizes, or by the difference. Here
the sum is used: a larger sum means more tokens. If there is a
correlation with size, it must arise because higher token counts are
not properly normalized. In other words, two large regions will
have more tokens, leading to higher type counts, which directly leads
to higher distances. Smaller regions will lead to lower distances.

\begin{table}
\begin{tabular}{l|rrrrr}
& $R$ & $R^2$ & KL & JS & cos  \\ \hline
  Leaf-Ancestor&-0.38 & -0.26 & -0.37 & -0.40 & -0.37\\
  Trigram&0.12 & -0.12 & -0.16 & 0.14 & -0.18\\
  Dependency&-0.39 & -0.26 & -0.35 & -0.43 & -0.39\\
  Phrase-Structure Rules&0.06 & 0.15 & 0.00 & 0.03 & -0.10\\
  Phrase-Structure with Grandparents&0.08 & 0.19 & 0.07 & 0.04 & -0.09\\
  Unigram&-0.08 & -0.14 & -0.09 & -0.09 & -0.10\\
  Dependencies, MaltParser trained by Timbl&-0.35 & -0.23 & -0.28 & -0.37 & -0.37\\
  Dependency, Arc Labels&-0.44 & -0.26 & -0.40 & -0.48 & -0.34\\
  All Features Combined&-0.37 & -0.26 & -0.38 & -0.42 & -0.40\\
\end{tabular}
\caption{Size correlation for sample size 1000, 1 normalization}
\label{size-cor-1-1000}
\end{table}

\begin{table}
\begin{tabular}{l|rrrrr}
& $R$ & $R^2$ & KL & JS & cos  \\ \hline
  Leaf-Ancestor&-0.19 & -0.15 & -0.16 & -0.24 & -0.36\\
  Trigram&\textit{0.30*} & 0.08 & 0.19 & 0.08 & -0.39\\
  Dependency&-0.17 & -0.06 & -0.08 & -0.26 & -0.41\\
  Phrase-Structure Rules&0.52** & \textit{0.40**} & 0.30* & 0.47** & -0.21\\
  Phrase-Structure with Grandparents&0.54** & 0.43** & 0.37** & 0.50** & -0.22\\
  Unigram&-0.09 & -0.13 & -0.11 & -0.13 & -0.13\\
  Dependencies, MaltParser trained by Timbl&-0.08 & 0.02 & 0.09 & -0.14 & -0.39\\
  Dependency, Arc Labels&-0.32 & -0.16 & -0.26 & -0.40 & -0.35\\
  All Features Combined&-0.15 & -0.11 & -0.10 & -0.25 & -0.42\\
\end{tabular}
\caption{Size correlation for complete corpora, 1 normalization}
\label{size-cor-1-full}
\end{table}

\begin{table}
\begin{tabular}{l|rrrrr}
& $R$ & $R^2$ & KL & JS & cos  \\ \hline
  Leaf-Ancestor&\textit{0.35*} & 0.36** & 0.06 & 0.27 & -0.32\\
  Trigram&\textit{0.75**} & \textit{0.63**} & \textit{0.46**} & \textit{0.68**} & -0.24\\
  Dependency&\textit{0.46**} & \textit{0.44**} & 0.14 & \textit{0.38**} & -0.33\\
  Phrase-Structure Rules&\textit{0.85**} & \textit{0.59**} & 0.36** & \textit{0.85**} & -0.34\\
  Phrase-Structure with Grandparents&\textit{0.88**} & \textit{0.66**} & 0.40** & \textit{0.88**} & -0.36\\
  Unigram&0.38** & 0.35** & 0.14 & 0.19 & -0.04\\
  Dependencies, MaltParser trained by Timbl&\textit{0.44**} & \textit{0.41**} & 0.16 & \textit{0.39*} & -0.30\\
  Dependency, Arc Labels&0.20 & 0.28* & -0.00 & 0.09 & -0.28\\
  All Features Combined&\textit{0.58**} & \textit{0.48**} & 0.21 & \textit{0.47**} & -0.31\\
\end{tabular}
 \caption{Size correlation for sample size 1000, 5 normalizations}
 \label{size-cor-5-1000}
\end{table}

\begin{table}
\begin{tabular}{l|rrrrr}
& $R$ & $R^2$ & KL & JS & cos  \\ \hline
  Leaf-Ancestor&-0.55 & -0.38 & -0.26 & -0.53 & -0.17\\
  Trigram&-0.29 & -0.27 & -0.19 & -0.26 & -0.14\\
  Dependency&-0.61 & -0.43 & -0.27 & -0.58 & -0.18\\
  Phrase-Structure Rules&-0.21 & -0.08 & -0.04 & -0.22 & -0.14\\
  Phrase-Structure with Grandparents&-0.24 & -0.08 & -0.03 & -0.26 & -0.14\\
  Unigram&-0.38 & -0.25 & -0.30 & -0.32 & -0.08\\
  Dependencies, MaltParser trained by Timbl&-0.52 & -0.33 & -0.20 & -0.51 & -0.15\\
  Dependency, Arc Labels&-0.59 & -0.45 & -0.33 & -0.54 & -0.20\\
  All Features Combined&-0.61 & -0.44 & -0.26 & -0.55 & -0.18\\
\end{tabular}
\caption{Size correlation for complete corpora, 5 normalizations}
\label{size-cor-5-full}
\end{table}

A large number of parameter settings that include 5 iterations of
normalization correlate with corpus size. However, corpus size also
correlates with geographic distance at a rate of 0.31 for $p < 0.01$
and travel distance at a rate of 0.32 for $p < 0.01$. This makes the
conclusion that these distances are invalid difficult to defend. Therefore,
results with 5 normalizations will be presented in the rest of this
chapter.

\subsubsection{Analysis}

The correlation of corpus size and dialect distance is a problem. It
is not a predicted as a side effect of the way dialect distance is
measured. The fact that travel distance also correlates with corpus
size at a rate of 0.32 confuses the issue further. Is corpus size the
determining variable? Or is there an unknown variable influencing all
three? Some possibilities are ``interviewer boundaries'', common in
corpora collected by multiple people \cite{chambers98}, or perhaps the
interviewers got better over time and collected longer interviews as
they moved throughout the country, or perhaps cultural differences
between the interviewer and interviewees caused some participants in
one area to talk more than in another area.

The high correlations between corpus size and the 5-normalization
distances are definitely worrying. They are so much higher than the
correlation of corpus size and travel distance that 5-normalized
distances might not be reliable.
% It appears that multiple rounds of
% normalization inadvertently re-introduce a dependency on size.
% TODO: This probably IS a bug in that only Fred norm can be
% iterated. Ratio norm should probably be in a separate loop like so:
% #ifdef RATIO_NORM
%   for(sample::iterator i = ab.begin(); i!=ab.end(); i++) {
%     i->second.first *= 2 * types / tokens;
%     i->second.second *= 2 * types / tokens;
%   }
% #endif
However, if 5-normalization introduces a dependency on corpus size,
then the distances from full-corpus comparisons should correlate even
more highly. This is not the case.

% TODO: I also should write this up when I have time
Alternatively, it is possible that the fixed-size sampling method is not doing its
job in eliminating size differences between corpora. Future work
should develop a method for normalizing a comparison between two full
corpora. It should avoid sampling, but also take the relative number
of sentences into account. It is not difficult to come up
with a simple method to do so, but it needs some checking to make sure
that the method is valid.

\section{Clusters}

Cluster dendrograms provide a visualization of which regions the
distance measures find to be similar.  Clusters answer the question of
whether $R$ is useful for dialectometry more precisely than correlation by
inducing grouping regions. These groups can be compared to
regions proposed by syntactic dialectology.

Within the same settings for sampling and number of normalization
iterations, the clusters based on sentence-length normalization alone are fairly
similar, regardless of measure and feature set. Changing the sampling
settings or the number of normalizations substantial reconfiguration.

For example, the clusters produced by $R$ (figure
\ref{cluster-1-r-trigram}) and Jensen-Shannon divergence are fairly
similar (figure \ref{cluster-1-js-trigram}). Both are based on trigram
features with sentence-length normalization only. Those dendrograms
differ from their 5-normalized equivalents, figures
\ref{cluster-5-r-trigram} and \ref{cluster-5-js-trigram}.

\begin{figure}
  \includegraphics[width=0.9\textwidth]{dist-1-1000-r-trigram-ratio-clusterward}
 \caption{Dendrogram With $R$
    measure and trigram features, 1 normalization, 1000 samples}
  \label{cluster-1-r-trigram}
\end{figure}

\begin{figure}
  \includegraphics[width=0.9\textwidth]{dist-1-1000-js-trigram-ratio-clusterward}
 \caption{Dendrogram With Jensen-Shannon
    measure and trigram features, 1 normalization, 1000 samples}
  \label{cluster-1-js-trigram}
\end{figure}

\begin{figure}
  \includegraphics[width=0.9\textwidth]{dist-1-full-r_sq-psg-ratio-clusterward}
 \caption{Dendrogram With $R^2$ measure and phrase-structure-rule features,
 1 normalization, complete corpora}
  \label{cluster-1-r_sq-psg}
\end{figure}


\begin{figure}
  \includegraphics[width=0.9\textwidth]{dist-5-1000-r-trigram-ratio-clusterward}
 \caption{Dendrogram With $R$ measure and trigram features, 5 normalizations, 1000 samples}
  \label{cluster-5-r-trigram}
\end{figure}

\begin{figure}
  \includegraphics[width=0.9\textwidth]{dist-5-1000-js-trigram-ratio-clusterward}
 \caption{Dendrogram With Jensen-Shannon
    measure and trigram features, 5 normalizations, 1000 samples}
  \label{cluster-5-js-trigram}
\end{figure}

The highest correlation of 1-normalized distances with travel
distance, 0.37, is given by $R^2$ measured over phrase-structure-rule
features, comparing full corpora. Those parameter settings produce the
dendrogram in figure \ref{cluster-1-r_sq-psg}. The highest
correlation of 5-normalized distances with travel distance, 0.26, is
given by the Jensen-Shannon measure and trigram features, comparing
1000-sentence samples of corpora. Its dendrogram is in figure
\ref{cluster-5-js-trigram}.

Unlike the significances, cosine similarity's dendrograms are fairly
similar to those of other features. See for example figure
\ref{cluster-5-cos-trigram}, with cosine, trigram features and
5 iterations of normalization.

\begin{figure}
 \includegraphics[width=0.9\textwidth]{dist-5-1000-cos-trigram-ratio-clusterward}
 \caption{Dendrogram with cosine measure and trigram features, 5
   normalizations}
  \label{cluster-5-cos-trigram}
\end{figure}


\subsection{Consensus Trees}

Consensus trees combine the results of cluster dendrograms, which
avoids the dendrograms' problem of instability, where small changes
in distances cause large re-arrangements in the tree. Only dendrograms
whose input distances were at least 95\% significant were used. That is, a
measure/feature set combination had to be non-bold in tables
\ref{sig-1-1000} to \ref{sig-5-full} to be included. The consensus
tree for full-corpora comparisons and 5 rounds of normalization is not
given because there is only one dendrogram that qualifies.

In addition, more dendrograms were used to build
the consensus tree of figure \ref{consensus-5-1000} than were used in
figures \ref{consensus-1-1000} and \ref{consensus-1-full}. Despite this, figure
\ref{consensus-5-1000} retains much more detail, indicating that its
constituent dendrograms, based on 5 rounds of normalization,
agree more than those with only 1 round of normalization.

The consensus trees are also grouped into clusters, which are then
mapped in figures \ref{map-consensus-1-1000} --
\ref{map-consensus-5-1000}. The maps of Sweden were provided by
Therese Leinonen and are the same those in \namecite{leinonen08}.  The
outline maps are used by permission of Therese Leinonen. The
multi-dimensional scaling and composite cluster maps were both
generated by the L04 package from the University of Groningen.
% TODO: CITE this, I think it's a Pieter Kliuweeg paper


\begin{figure}
\includegraphics[scale=0.7]{consensus-1-1000}
% \Tree[. {Villberga\\Viby\\Vaxtorp\\Torso\\Tors\.as\\StAnna\\Sproge\\Sorunda\\Skinnskatteberg\\Segerstad\\Ossjo\\Orust\\Norra Rorum\\Loderup\\Leksand\\K\"ola\\Jamshog\\Indal\\Frillesas\\Fole\\Faro\\Bredsatra\\Boda\\Bara\\Asby\\Arsunda\\Anundsjo\\Ankarsrum} [. {Floby\\Bengtsfors}  ] ]
\caption{Consensus Tree for 1000-samples and 1 normalization}
\label{consensus-1-1000}
\end{figure}

\begin{figure}
\includegraphics[scale=0.7]{consensus-1-full}
% \Tree[. {Villberga\\Viby\\Torso\\Tors\.as\\Sorunda\\Segerstad\\Ossjo\\Orust\\Norra Rorum\\Loderup\\Leksand\\K\"ola\\Indal\\Fole\\Boda\\Bara\\Asby\\Arsunda\\Anundsjo\\Ankarsrum}
%   [. {Vaxtorp\\Skinnskatteberg}  ]
%   [. {StAnna\\Frillesas}  ]
%   [. {Sproge\\Faro}  ]
%   [. {Jamshog\\Bredsatra}  ]
%   [. {Floby\\Bengtsfors}  ] ]
\caption{Consensus Tree for full corpus comparison and 1 normalization}
\label{consensus-1-full}
\end{figure}

\begin{figure}
\includegraphics[scale=0.7]{consensus-5-1000}
% \Tree[. {Villberga\\Viby\\Vaxtorp\\Torso\\StAnna\\Sproge\\Sorunda\\Skinnskatteberg\\Segerstad\\Orust\\Norra Rorum\\Leksand\\K\"ola\\Indal\\Frillesas\\Fole\\Floby\\Faro\\Boda\\Bengtsfors\\Bara\\Asby\\Arsunda\\Anundsjo\\Ankarsrum} [. {Loderup\\Bredsatra}  ] [. {Tors\.as\\Ossjo\\Jamshog}  ] ]
\caption{Consensus Tree for 1000-samples and 5 normalizations}
\label{consensus-5-1000}
\end{figure}

\begin{figure}
\includegraphics[scale=0.85]{Sverigekarta-Landskap-consensus-1-1000}
\caption{Consensus Tree for 1000-samples and 1 normalization, Mapped}
\label{map-consensus-1-1000}
\end{figure}

\begin{figure}
\includegraphics[scale=0.85]{Sverigekarta-Landskap-consensus-1-full}
\caption{Consensus Tree for full corpus comparison and 1 normalization, Mapped}
\label{map-consensus-1-full}
\end{figure}

\begin{figure}
\includegraphics[scale=0.85]{Sverigekarta-Landskap-consensus-5-1000}
\caption{Consensus Tree for 1000-samples and 5 normalizations, Mapped}
\label{map-consensus-5-1000}
\end{figure}

% It would still be cool to eliminate only the non-significant distances
% and re-run the clusters. (I can't remember if that's easily possible
% with R though, it may only be a feature of MDS.)

% TODO: Try these two again, excluding cosine. Because I believe cosine sucks
% or at least is a Rogue Element.
% Later: Probably not worth it.

% Just the ratio ones that are significantly correlated with travel
% distance.
% However: This is even more of a mess than the freq results.
% [. {s0} [. {}
%     [. {} [. {Köla} [. {Ossjo} [. {Torsås\\Jamshog}  ] ] ]
%           [. {Villberga\\Viby\\Torso\\StAnna\\Sorunda\\Norra Rorum\\Frillesas\\Boda\\Bara}
%              [. {Loderup\\Bredsatra}  ] ] ]
%     [. {Orust\\Leksand\\Indal\\Fole\\Faro\\Asby\\Arsunda\\Anundsjo}
%        [. {Vaxtorp\\Skinnskatteberg}  ]
%        [. {Ankarsrum}
%           [. {Segerstad} 
%              [. {Bengtsfors}
%                 [. {Sproge\\Floby}  ] ] ] ] ] ] ]

\subsubsection{Analysis}

The cluster dendrograms are dangerous
to interpret too closely on their own; the instability of a single
dendrogram means that small clusters cannot be analyzed reliably. For
example, in figure \ref{cluster-5-r-trigram}, a two-way split
between the regions on the top and bottom of the page is
obvious, and a three-way split is easy to argue for, but outliers like
Anundsj\"o and \.Arsunda are likely to shift from group to group in
other dendrograms.

It is safer to analyze the consensus trees; the smoothing effect of
taking the majority rule of each cluster will show where the optimal
cutoff for splitting clusters is. The three consensus trees in figures
\ref{consensus-1-1000} -- \ref{consensus-5-1000} vary in amount of
detail but share most details.

For 1000-sentence samples and 1 round of normalization, there is one
cluster: Floby and Bengtsfors. Full-corpus comparison finds
another cluster: J\"amshog, \"Ossj\"o and Tors\.as. Finally,
1000-sentence samples and 5 rounds of normalization finds another
cluster consisting of L\"oderup and Breds\"atra. It also finds
a large two-way split between the regions and adds Sproge to the first
cluster with Floby and Bengtsfors. To aid further analysis, the
clusters are assigned colors, which are detailed in figures
\ref{blue-cluster} -- \ref{orange-cluster}. 

\begin{figure}
\begin{itemize}
\item Floby
\item Bengtsfors
\item Sproge (for 1000-sample, 5-normalization)
\end{itemize}
\caption{Blue Cluster}
\label{blue-cluster}
\end{figure}

\begin{figure}
\begin{itemize}
\item J\"amsh\"og
\item Tors\.as
\item \"Ossj\"o
\end{itemize}
\caption{Red Cluster}
\label{red-cluster}
\end{figure}

\begin{figure}
\begin{itemize}
\item Breds\"atra
\item L\"oderup
\end{itemize}
\caption{Yellow Cluster}
\label{yellow-cluster}
\end{figure}

\begin{figure}
\begin{itemize}
\item Leksand
\item Indal
\item Segerstad
\item Floby
\item Bengtsfors
\item Sproge
\item Skinnskatteberg
\item Orust
\item V\.axtorp
\item F\.ar\"o
\item Asby
\item \.Arsunda
\item Anundsj\"o
\item Ankarsrum
\item Fole
\end{itemize}
\caption{Cyan Cluster}
\label{cyan-cluster}
\end{figure}

\begin{figure}
\begin{itemize}
\item Viby
\item Bara
\item S:t Anna
\item Frilles\.as
\item J\"amshog
\item Tors\.as
\item \"Ossj\"o
\item K\"ola
\item L\"oderup
\item Breds\"atra
\item Villberga
\item Tors\"o
\item Norra R\"orum
\item Sorunda
\item B\"oda
\end{itemize}
\caption{Orange Cluster}
\label{orange-cluster}
\end{figure}

When these clusters are mapped onto the geography of Sweden, some
patterns are visible. Since figure \ref{consensus-5-1000} is strictly
more complex than the preceding two, it is used as the basis for this
analysis--see map \ref{map-consensus-5-1000}. The large two-way split
is between the orange and cyan clusters. The orange cluster, which
includes red and yellow clusters, forms two horizontal bands across
Sweden. The centers of the orange cluster appear to be Stockholm and
Malm\"o. Meanwhile, the red and yellow clusters form a boundary along
the northern border of Sk\.ane and Blekinge counties.

Meanwhile, the cyan cluster, which includes the blue cluster, seems to
represent the countryside of Sweden. On the other hand, because the
blue cluster is near G\"oteborg, it might be better characterized
simply as ``non-Stockholm''.


\subsection{Composite Cluster Maps}

Composite cluster maps use an underlying technique similar to
consensus trees--cluster dendrograms, but they combine and present the
information in a very different way. They, too, provide a stabler view
of the groups that regions form when clustered. This view, however,
emphasizes the boundaries between regions. The result looks
much more like the traditional isogloss boundaries of
dialectology.

The two composite cluster maps in figures \ref{map-composite-1-1000}
-- \ref{map-composite-5-1000} are the composite of the same
dendrograms used as input for the consensus trees: all-significant
parameter settings, divided by type of normalization (sentence-length
only or ratio added as well).

\begin{figure}
\includegraphics[scale=0.82]{Sverigekarta-cluster-1-1000}
\caption{Composite Cluster Map for 1000-sample, 1 normalization}
\label{map-composite-1-1000}
\end{figure}

\begin{figure}
\includegraphics[scale=0.82]{Sverigekarta-cluster-1-full}
\caption{Composite Cluster Map for complete corpora, 1 normalization}
\label{map-composite-1-full}
\end{figure}

\begin{figure}
\includegraphics[scale=0.82]{Sverigekarta-cluster-5-1000}
\caption{Composite Cluster Map for complete corpora, 5 normalizations}
\label{map-composite-5-1000}
\end{figure}

All three composite clusters maps provide a picture similar to the
consensus tree map \ref{map-consensus-5-1000} of the previous
section. The north-to-south gradient is supported by the
weak horizontal boundaries present up and down Sweden.

Of these boundaries, the one between Sk\.ane and the rest of Sweden is
the strongest. Due to the lack of interview sites in the middle of
south Sweden, the boundary is drawn further north than it
traditionally appears, but this is an effect of the software the
produced the figure. Notice that there is also a boundary between
J\"amshog, Tors\.as, and \"Ossjo\" and the other sites, especially
visible in maps\ref{map-composite-1-1000} and
\ref{map-composite-5-1000}. Their presence along the northern border
of Sk\.ane is one reason why its boundary with the rest of Sweden is
so strong.

\begin{sloppypar}
  Compared to the consensus tree maps, the composite cluster maps
  cannot support the city/country distinction because there is no way
  to identify distant areas by their color. On the other hand, it is
  possible to detect the relative strength of a boundary. To combine
  these two features, multi-dimensional scaling is needed.
\end{sloppypar}
% But of course MDS maps can't be combined into a consensus...

% However, K\"ola and Frilles\.as still separate fairly well from their
% neighbors. These sites are on the edges of the country and have strong borders
% with surrounding, Like the cluster J\"amshog, Tors\.as and \"Ossj\"o,
% these sites are different from the others. However, they don't have
% any geographic coherence, so it is more likely these are remnants of a
% dialect that was historically wider spread and has since receded.


\section{Multi-Dimensional Scaling}

\begin{sloppypar}
  Multi-dimensional scaling (MDS) plays a similar role to clusters,
  condensing the high-dimensional information into an
  easier-to-understand form.  It differs, however, in producing
  gradient numbers, not binary trees: only enough scaling is done to
  produce the desired number of dimensions, and there is no exclusive
  membership in a single group. This also means that MDS maps are more
  stable than dendrograms.  Also, because of the way that the
  3-dimensional points map to colors, the maps vary. However, they
  are still comparable: if two regions are blue in one map and both
  are orange in another, then they have the same relation to each
  other.
\end{sloppypar}


The maps shown here in figures \ref{mds-1-1000-js-trigram} --
\ref{mds-5-1000-js-trigram} are from the same parameter settings as the
dendrograms, with the addition of the all-combined feature set. This
provides a combined MDS view somewhat analogous to the consensus trees or
composite clusters for the cluster dendrograms.

\begin{figure}
\includegraphics[scale=0.82]{Sverigekarta-mds-1-1000-r-trigram-ratio}
\caption{$R$ measure with trigram features, 1000-sentence sampling and
  1 round of normalization}
\label{mds-1-1000-r-trigram}
\end{figure}

\begin{figure}
\includegraphics[scale=0.82]{Sverigekarta-mds-1-1000-js-trigram-ratio}
\caption{Jensen-Shannon measure with trigram features, 1000-sentence sampling and
  1 round of normalization}
\label{mds-1-1000-js-trigram}
\end{figure}

\begin{figure}
\includegraphics[scale=0.82]{Sverigekarta-mds-1-full-r-trigram-ratio}
\caption{$R$ measure with trigram features, full-corpus comparison and
  1 round of normalization}
\label{mds-1-full-r-trigram}
\end{figure}

\begin{figure}
\includegraphics[scale=0.82]{Sverigekarta-mds-1-full-r_sq-psg-ratio}
\caption{$R^2$ measure with phrase-structure-rule features, full-corpus comparison and
  1 round of normalization}
\label{mds-1-full-r_sq-psg}
\end{figure}

\begin{figure}
\includegraphics[scale=0.82]{Sverigekarta-mds-5-1000-r-trigram-ratio}
\caption{$R$ measure with trigram features, 1000-sentence sampling and
  5 rounds of normalization}
\label{mds-5-1000-r-trigram}
\end{figure}

\begin{figure}
\includegraphics[scale=0.82]{Sverigekarta-mds-5-1000-js-trigram-ratio}
\caption{Jensen-Shannon measure with trigram features, 1000-sentence sampling and
  5 rounds of normalization}
\label{mds-5-1000-js-trigram}
\end{figure}

Despite the differences between MDS and the preceding methods, the
similar results are evident; the maps (figures
\ref{mds-1-1000-r-trigram} -- \ref{mds-5-1000-js-trigram}) all show
the same patterns as the other methods. That is, there is a general
north-to-south gradience, especially easy to see in map
\ref{mds-1-1000-js-trigram}. There is a strong southern cluster,
visible in all of the diagrams. And there is a general two-way
distinction between city and country.

The main contribution that the MDS maps make is that the
north-to-south gradient is more obviously gradient. In other words, it
is easier to see the gradation from north to south. For example, in
figure \ref{mds-1-full-r_sq-psg}, looking from the north to south, the
colors change quickly close to Stockholm, then fade to green further
south, then transition back to blues and purples further south, in
Sk\.ane.

The Stockholm and Malm\"o areas, which are in the same cluster in the
consensus tree maps, are here seen to be similar without being
identical. For example, in figure \ref{mds-5-1000-js-trigram}, the
Stockholm area is a shade of blue-green while the Malm\"o area is a
shade of blue-grey. Also in figure \ref{mds-5-1000-js-trigram},
Sk\.ane and Blekinge are grey: clearly similar but not identical to
Malm\"o.

\section{Features}

Ranked features answer the question of agreement with dialectology
more precisely than the previous two sections. Feature ranking has two
advantages in precision: first, it can reveal aggregate differences that may
not be noticeable without counting a large corpus; second, it can
point out rare features that only occur in one kind of corpus. The
first kind of features are unlikely to be noticed by linguists without
the aid of computers, whereas the second kind are the rare features
that are easy for linguists to notice.

There are two sets of rankings on display here; the first set is the
previous normalization for sentence size, whereas the second is
normalized for relative overuse, based on \quotecite{wiersma09}
normalization.  Without the overuse normalization, the top-ranked
features will tend to be the most common ones, those found in almost
every sentence in the interview. These common features tend to
highlight gradient differences: differences in quantity but not in
quality. In contrast, the overuse normalization allows us to see which
features happen only a few times in one side of the comparison and not
at all in the other. This is closer to a traditional linguistic
analysis.

In addition, only features that appear in both groups were ranked;
although features that only appear in one or the other can be
interesting, they tend to be noisy in features extracted from
automatically annotated corpora. It is not possible to tell which
unique features are interesting and which are noise, especially when
using the overuse normalization, which makes rarely occurring features
rank similarly to common ones.

These results compare clusters from the consensus trees
based on 1 round of normalization (figures \ref{consensus-1-1000} and
\ref{consensus-1-full}) as well as the consensus tree based on 5
rounds of normalization and a 1000-sentence sample (figure
\ref{consensus-5-1000}. The consensus tree for 5 rounds or
normalization and full-corpus comparisons only had one tree for input
and was not usable. Given these three consensus trees, the groups in
table \ref{feature-ranking-clusters} are the relevant ones for analysis.

There are four clusters, three small and one large which contains the remainder of
the sites. Cluster A, containing Floby and Bengtsfors, appears in all
three consensus trees. Its features are colored blue in the following
figures. Cluster B, containing Jamshog, Torsas and Ossjo, appears in the
second two trees. It features are colored red. Cluster C, containing
Loderup and Bredsatra, appears only in the third tree. Its features
are colored yellow. The remainder of the sites are in Cluster D;
the third consensus tree differs from the first two in splitting the
remainder into two groups, but this division is ignored here to reduce
the number of comparisons. Between large groups of sites, such
comparisons are unlikely to be informative anyway.

\begin{table}
  \begin{enumerate}
   \item[A] (Blue) Floby, Bengtsfors
    \item[B] (Red) J\"amshog, \"Ossj\"o, Tors\.as
    \item[C] (Yellow) L\"oderup, Breds\"atra
    \item[D] (Cyan) Segerstad, K\"ola, S:t Anna, Sorunda, Norra Rorum,
      Villberga, Torso, Boda, Frilles\.as, Indal, Leksand, Anundsj\"o,
      \.Arsunda, Asby, Orust, V\.axtorp, Fole, Sproge, F\.ar\"o,
      Ankarsrum, Skinnskatteberg
  \end{enumerate}
  \caption{Clusters discussed}
  \label{feature-ranking-clusters}
\end{table}

For each pair of clusters, I rank and analyze the input features by
comparing feature differences. The features presented here are the ten
highest ranked features for a particular comparison. Although each
feature set has ten features ranked here, they are better thought of
as two sets of five features differences. The top five positive
features are shown as are the top five negative features.

This has two advantages. It splits the features so that both the
positive and negative evidence are always visible; otherwise, in some
cases, if one side is strong enough, the other would be pushed out of
the top ten. However, it still allows the relative weight of evidence
to be estimated. For example, if some cluster has some idiosyncratic
features, most of the features will be positive, meaning that most of
the distance comes from features typical of this cluster. The two-part
feature will show this: the five positive features will have much
higher values than the five negative features.


The first subsection, \ref{feature-ranking-complete}, shows all
comparisons between regions for a single parameter setting: trigram
features, 1000-sentence sampling and sentence-size normalization
only. Besides unigrams, these are the parameters that give the highest
correlation with travel distance for 1000-sentence sampling.

In the next subsection, \ref{feature-ranking-overuse}, the overuse
normalization is added, keeping other parameter settings the same.

The third subsection, \ref{feature-ranking-feature-sets},
a single comparison between cluster A and cluster B is given for
all feature sets.

In the final subsection, \ref{feature-ranking-psg}, the high-ranked
phrase-structure rules are given.

The most common parts of speech are given below. The complete list is
given in Appendix X. (TODO: Move most of this list to an
appendix).

\begin{itemize}
\item $++$ = coordinating conjunction
\item AB = adverb
\item AJ = adjective
\item AN = adjectival noun
\item AV = verb ``vara'' (be)
\item BV = verb ``bli(va)'' (become) %
% \item EH = hesitation
\item EN = indefinite article
\item FV = verb ``f\.a'' (get) %
\item GV = verb ``g\"ora'' (do) %
\item HV = verb ``hava'' (have) %
\item I? = question mark %
\item IC = quotation mark %
\item ID = idiom
\item IG = other punctuation mark %
\item IK = comma, correction
\item IM = infinitive marker
\item IP = period
% \item IQ = colon
% \item IR = parenthesis
% \item IS = semicolon
% \item IT = dash
\item IU = exclamation mark
\item KV = ``komma at'' (periphrastic future)
\item MN = meta-noun
\item MV = verb ``m\.aste'' (must)
\item NJ = falling juncture
\item NN = noun
\item PN = proper name
\item PO = pronoun
\item PR = preposition
\item PU = list item
% \item QQ = ?
\item QV = verb ``kunna'' (can)
% \item RJ = level juncture
\item RO = numeral
\item SP = present participle
\item SV = verb ``skola'' (shall)
\item TP = perfect participle
% \item UJ = rising juncture
\item UK = subordinating conjunction
% \item UU = exclamation
\item VN = verbal noun
\item VV = other verb
\item WV = verb ``vilja'' (want)
\item YY = Interjection
\item XX = Unclassifiable
\end{itemize}

%%% END FORK

\subsection{Trigram Features}
\label{feature-ranking-complete}

The analysis will start with trigram features without the overuse
normalization, since trigrams have the highest rate of significance of
the non-combined feature sets. (The combined feature set is not
presented because the mixed feature types make it difficult to read.)

As mentioned above, the top-ranked trigrams are common, typical of the
core of the sentence. Cluster A's typical trigrams, for example,
typically involve a pronoun or a verb or both: PO-AV-AB
(pronoun-copula-adverb), $++$-PO-AV (conjunction-pronoun-copula) and
PO-VV-AB (pronoun-verb-adverb). The same is of the other clusters for
the most part. Unfortunately, this makes it hard to say interesting
things about the difference in feature distribution. It does appear
that clusters B and C have heavier use of adverbs and of
conjunctions. The comparison between cluster A and cluster B even
highlights the trigram AB-AB-AB as important.

\begin{figure}
  \includegraphics[scale=1.2]{clusterA-clusterB-feat-5-1000-trigram-ratio}
  \caption{cluster A $\Leftrightarrow$ cluster B, trigram features}
\end{figure}
\begin{figure}
  \includegraphics[scale=1.2]{clusterA-clusterC-feat-5-1000-trigram-ratio}
  \caption{cluster A $\Leftrightarrow$ cluster C, trigram features}
\end{figure}
\begin{figure}
  \includegraphics[scale=1.2]{clusterA-clusterD-feat-5-1000-trigram-ratio}
  \caption{cluster A $\Leftrightarrow$ cluster D, trigram features}
\end{figure}


\begin{figure}
  \includegraphics[scale=1.2]{clusterB-clusterC-feat-5-1000-trigram-ratio}
  \caption{cluster B $\Leftrightarrow$ cluster C, trigram features}
\end{figure}
\begin{figure}
  \includegraphics[scale=1.2]{clusterB-clusterD-feat-5-1000-trigram-ratio}
  \caption{cluster B $\Leftrightarrow$ cluster D, trigram features}
\end{figure}
\begin{figure}
  \includegraphics[scale=1.2]{clusterC-clusterD-feat-5-1000-trigram-ratio}
  \caption{cluster C $\Leftrightarrow$ cluster D, trigram features}
\end{figure}

\subsection{Trigrams with Overuse Normalization}
\label{feature-ranking-overuse}

Given this lack of information, there are two dimensions along which
the comparisons can be altered: normalization and feature
set. Starting with normalization, let us add the overuse normalization
technique. Differences appear immediately. First, the balance of
feature weight obviously differs here. For example, in the comparison
between cluster A and cluster B, the features of cluster A are more
important in distinguishing the two than the features of cluster
B. The comparison between cluster A and cluster D is so lop-sided that
cluster D contributes no features at all.

With the overuse normalization, cluster A has two interesting
patterns. First, the trigrams it overuses are filled with indefinite
articles (EN) and prepositions (PR). Examples include VV-EN-AB
(verb-indefinite-adverb), PR-EN-AB (preposition-indefinite-adverb) and
PR-EN-VN (preposition-indefinite-verbal noun), as well as IM-PR-NN
(infinitive marker-preposition-noun) and PR-ID-PR
(preposition-idiom-preposition). Second, the trigrams it underuses
mostly end with pronouns: 4 of 5 trigrams in the comparison with
cluster B and 4 or 5 in the comparison with cluster C. Even in the
comparison with cluster D, 4 of 5 of the ``least overused'' trigrams
end with pronouns. (The low values in the bottom half of the
comparison with cluster D are not underused by cluster A, because
cluster D has no unique features here. Instead they are the ``least
overused'' by cluster A.)

Cluster B shows one interesting pattern: overuse of sk\"ola (shall),
including an interesting trigram SV-QV-AB (shall verb-can
verb-adverb). Although this could be a mistake on the part of the
tagger, the different forms of this verb are limited, so this is
unlikely: identifying them is not hard. Instead it points to the
possibility of double modals.
%% a quick search suggests that Fennell and Butters (1996) finds
%% evidence in German and Scandinavian languages...but it's a book ro
%% something. Google Scholar has no link, just a wimpy citation.
%% Also:
%% Modals and double modals in the Scandinavian languages
%% Working papers in Scandinavian syntax
%% Thrainsson and Vikner 1995 (but focussing on Danish and Icelandic)

Cluster C doesn't gain any interesting patterns with overuse
normalization except for a surprising variety in the verbs: g\"ora
(do), hava (have), kunna (get), sk\"ola (shall), vara (be) and vilja
(want). Many uses of adverbs show up as well. It is not clear what
either of these patterns mean linguistically, however.
% I have no idea whether to make that verb singular or plural.
% So like whatever.

Cluster D gives no information whatsoever when the overuse
normalization is added, simply because it has no informative
features. This is expected, given its nature as a combination of many
sites. The tradeoff of more informative features for the smaller
clusters is worthwhile.

\begin{figure}
  \includegraphics[scale=1.2]{clusterA-clusterB-feat-5-1000-trigram-over}
  \caption{cluster A $\Leftrightarrow$ cluster B, trigram features
    with overuse normalization}
\end{figure}
\begin{figure}
  \includegraphics[scale=1.2]{clusterA-clusterC-feat-5-1000-trigram-over}
  \caption{cluster A $\Leftrightarrow$ cluster C, trigram features
    with overuse normalization}
\end{figure}
\begin{figure}
  \includegraphics[scale=1.2]{clusterA-clusterD-feat-5-1000-trigram-over}
  \caption{cluster A $\Leftrightarrow$ cluster D, trigram features
    with overuse normalization}
\end{figure}


\begin{figure}
  \includegraphics[scale=1.2]{clusterB-clusterC-feat-5-1000-trigram-over}
  \caption{cluster B $\Leftrightarrow$ cluster C, trigram features
    with overuse normalization}
\end{figure}
\begin{figure}
  \includegraphics[scale=1.2]{clusterB-clusterD-feat-5-1000-trigram-over}
  \caption{cluster B $\Leftrightarrow$ cluster D, trigram features
    with overuse normalization}
\end{figure}
\begin{figure}
  \includegraphics[scale=1.2]{clusterC-clusterD-feat-5-1000-trigram-over}
  \caption{cluster C $\Leftrightarrow$ cluster D, trigram features
    with overuse normalization}
\end{figure}

\subsection{Variation Across Feature Sets}
\label{feature-ranking-feature-sets}

Moving to other features sets with overuse normalization,
leaf-ancestor paths and leaf-head paths give additional information
about cluster A that lead to the conclusion its defining
characteristic is simple sentences, simpler at least than the other
clusters. Specifically, cluster A's overused leaf-ancestor paths
include few nested sentences. This contrasts sharply with cluster B
and cluster C, which include many nested sentences. Cluster A does
have complex paths, but they feature prepositional phrases. (Note: NAC
stands for ``not a constituent'' and indicates that the parser could
not decide what the correct constituent was at that point.) (Or that
there are crossing branches, which is less common.)

This characteristic of cluster A appears in the leaf-head paths as
well; cluster A's paths contain many [adjective]-noun-preposition
sequences, but few verb-verb sequences that indicate nested
phrases. Again, cluster B and cluster C have many of these
sequences. Both clusters have a number of overused adverb features as
well, similar to the trigram results. Note that comparison to cluster
D is less interesting. Because it has fewer unique characteristics,
when compared to it, clusters A, B and C show more generic
characteristics. For example, all three clusters show that their
sentences are generally more complex than the general sites in cluster D.

\begin{figure}
  \includegraphics[scale=1.2]{clusterA-clusterB-feat-5-1000-path-over}
  \caption{cluster A $\Leftrightarrow$ cluster B, leaf-ancestor path features}
\end{figure}
\begin{figure}
  \includegraphics[scale=1.2]{clusterA-clusterB-feat-5-1000-trigram-over}
  \caption{cluster A $\Leftrightarrow$ cluster B, trigram features}
\end{figure}
\begin{figure}
  \includegraphics[scale=1.2]{clusterA-clusterB-feat-5-1000-dep-over}
  \caption{cluster A $\Leftrightarrow$ cluster B, dependency features}
\end{figure}
\begin{figure}
  \includegraphics[scale=1.2]{clusterA-clusterB-feat-5-1000-psg-over}
  \caption{cluster A $\Leftrightarrow$ cluster B, phrase-structure
    rule features}
\end{figure}
\begin{figure}
  \includegraphics[scale=1.2]{clusterA-clusterB-feat-5-1000-grand-over}
  \caption{cluster A $\Leftrightarrow$ cluster B, phrase-structure
    rules features, with grandparent}
\end{figure}
\begin{figure}
  \includegraphics[scale=1.2]{clusterA-clusterB-feat-5-1000-unigram-over}
  \caption{cluster A $\Leftrightarrow$ cluster B, unigram features}
\end{figure}
\begin{figure}
  \includegraphics[scale=1.2]{clusterA-clusterB-feat-5-1000-redep-over}
  \caption{cluster A $\Leftrightarrow$ cluster B, dependency features,
MaltParser trained by Timbl}
\end{figure}
\begin{figure}
  \includegraphics[scale=1.2]{clusterA-clusterB-feat-5-1000-deparc-over}
  \caption{cluster A $\Leftrightarrow$ cluster B, dependency features
    with arc labels}
\end{figure}
\begin{figure}
  \includegraphics[scale=1.2]{clusterA-clusterB-feat-5-1000-all-over}
  \caption{cluster A $\Leftrightarrow$ cluster B, all combined features}
\end{figure}


\subsection{Phrase-structure rule features}
\label{feature-ranking-psg}

\begin{figure}
  \includegraphics[scale=1.2]{clusterA-clusterB-feat-5-1000-psg-ratio}
  \caption{cluster A $\Leftrightarrow$ cluster B, phrase-structure
    rule features}
\end{figure}
\begin{figure}
  \includegraphics[scale=1.2]{clusterA-clusterC-feat-5-1000-psg-ratio}
  \caption{cluster A $\Leftrightarrow$ cluster C, phrase-structure rule features}
\end{figure}
\begin{figure}
  \includegraphics[scale=1.2]{clusterA-clusterD-feat-5-1000-psg-ratio}
  \caption{cluster A $\Leftrightarrow$ cluster D, phrase-structure rule features}
\end{figure}


\begin{figure}
  \includegraphics[scale=1.2]{clusterB-clusterC-feat-5-1000-psg-ratio}
  \caption{cluster B $\Leftrightarrow$ cluster C, phrase-structure rule features}
\end{figure}
\begin{figure}
  \includegraphics[scale=1.2]{clusterB-clusterD-feat-5-1000-psg-ratio}
  \caption{cluster B $\Leftrightarrow$ cluster D, phrase-structure rule features}
\end{figure}
\begin{figure}
  \includegraphics[scale=1.2]{clusterC-clusterD-feat-5-1000-psg-ratio}
  \caption{cluster C $\Leftrightarrow$ cluster D, phrase-structure rule features}
\end{figure}

Analysis of the phrase-structure-rule features is difficult because of
all the noise. Features like S$\to++$-AB (conjunction-adverb)
S$\to$FV-PO-AB-VV (get verb-pronoun-adverb-verb) are hard to describe
as anything but junk rules created by the parser. On the other hand,
there are a lot of linguistically odd but reasonable rules like
S$\to$PO-AV-NP-IP (pronoun-copula-noun phrase-period), which makes a
certain kind of sense if you can be persuaded that copular sentences
are special enough to deserve their own rule. (Remember that
statistical parsers trained on interview data are particularly
susceptible to this kind of persuasion.)

Overall both normalizations leave something to be desired; without
overuse normalization, only very common features appear. These
features convey only basic information, making it hard to identify
characteristics of a cluster. On the other hand, the overuse
normalization is susceptible to noise, especially for more error-prone
feature sets. Even though more detail may be available with this
normalization step, the features must be inspected for general trends
because individual features are not necessarily reliable.


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "dissertation.tex"
%%% End: 
